{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "input_file = \"./data/incidents/incident_34/DeviceFileEvents.csv\"\n",
    "output_file = 'a.csv'\n",
    "expected_columns = 58  # Set this to the expected number of columns in your table\n",
    "\n",
    "# Open input and output files\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    # Use ❖ as the delimiter\n",
    "    reader = csv.reader(infile, delimiter='❖')\n",
    "    writer = csv.writer(outfile, delimiter='❖')\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) == expected_columns:\n",
    "            writer.writerow(row)  # Write valid row to output\n",
    "        else:\n",
    "            print(f\"Skipping row: {row}\")  # Log or handle the bad row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11472"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"./data/incidents/incident_34/DeviceFileEvents.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-06-26 11:30:07.576330+00:00'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TimeGenerated'][11471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "files = [\"./data/incidents/incident_55/DeviceRegistryEvents/DeviceRegistryEvents_0.csv\", \"./data/incidents/incident_55/DeviceRegistryEvents/DeviceRegistryEvents_1.csv\"]\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "    print(len(df.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "def convert_double_quotes(input_file, output_file):\n",
    "    df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "    df.replace('\"', \"'\", regex=True, inplace=True)\n",
    "    df.to_csv(output_file, sep=\"❖\", encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "def convert_double_quotes_for_one_folder(folder):\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            # end in csv\n",
    "\n",
    "            if not file.endswith(\".csv\"):\n",
    "                continue\n",
    "            print(file)\n",
    "            input_file = os.path.join(root, file)\n",
    "            convert_double_quotes(input_file, input_file)\n",
    "    \n",
    "need_conversion = [\n",
    "    \"./data/incidents/incident_34/DeviceFileEvents.csv\",\n",
    "    \"./data/incidents/incident_55/DeviceRegistryEvents/DeviceRegistryEvents_0.csv\",\n",
    "    \"./data/alphineskihouse/DeviceRegistryEvents/DeviceRegistryEvents_3.csv\",\n",
    "    \"./data/alphineskihouse/DeviceFileEvents/DeviceFileEvents_2.csv\"\n",
    "]\n",
    "\n",
    "for file in need_conversion:\n",
    "    convert_double_quotes(file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/alphineskihouse/DeviceRegistryEvents/DeviceRegistryEvents_3.csv\"\n",
    "\n",
    "convert_double_quotes(input_file, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeviceFileEvents\n",
    "\n",
    "# input_file = \"./data/alphineskihouse/DeviceFileEvents\"\n",
    "\n",
    "# # convert_double_quotes(input_file, input_file)   \n",
    "# convert_double_quotes_for_one_folder(input_file)\n",
    "\n",
    "\n",
    "# input_file = \"./data/alphineskihouse/DeviceFileEvents/DeviceFileEvents_16.csv\"\n",
    "\n",
    "# convert_double_quotes(input_file, input_file)\n",
    "\n",
    "\n",
    "input_file = \"./data/alphineskihouse/DeviceFileEvents/DeviceFileEvents_2.csv\"\n",
    "# df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "\n",
    "convert_double_quotes(input_file, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeGenerated\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(start_time, end_time)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mredownloadfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/alphineskihouse/DeviceFileEvents/tmp/DeviceFileEvents_2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m, in \u001b[0;36mredownloadfile\u001b[0;34m(input_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mredownloadfile\u001b[39m(input_file, ):\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(input_file, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❖\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# get time range: TimeGenerated\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeGenerated\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def redownloadfile(input_file, ):\n",
    "    df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "    # get time range: TimeGenerated\n",
    "    start_time = df['TimeGenerated'].min()\n",
    "    end_time = df['TimeGenerated'].max()\n",
    "    print(start_time, end_time)\n",
    "    \n",
    "\n",
    "redownloadfile(\"./data/alphineskihouse/DeviceFileEvents/tmp/DeviceFileEvents_2.csv\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: DeviceFileEvents, Total count: 45327, Size per entry: 1513.7285 Bytes, Total size: 65.43423816633224 MB, Row per query: 39637.0, Estimate table count: 1.0\n",
      "Time chunk: 142 hours\n",
      "Chunk 1: 2024-06-25 22:33:41.981355+00:00 - 2024-06-27 12:53:48.292137+00:00\n",
      "Chunk 2: 2024-06-27 12:53:59.017583+00:00 - 2024-06-27 21:09:32.194768+00:00\n",
      "Reached end of the table. Exiting.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from download_logs import download_logs\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "Alpine = \"e34d562e-ef12-4c4e-9bc0-7c6ae357c015\"\n",
    "\n",
    "# 2024-06-25 22:33:41.981355+00:00 2024-06-27 21:09:34.497757+00:00\n",
    "\n",
    "download_logs(Alpine, [\"DeviceFileEvents\"], datetime(2024, 6, 25, 22, 33, 41, tzinfo=timezone.utc), datetime(2024, 6, 27, 21, 9, 34, tzinfo=timezone.utc), \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/incidents/incident_55/DeviceRegistryEvents/DeviceRegistryEvents_0.csv\"\n",
    "df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "df = df.replace('\"', \"'\", regex=True)\n",
    "\n",
    "with open(input_file, 'w', newline='') as outfile:\n",
    "    df.to_csv(outfile, sep='❖', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70975"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"./data/incidents/incident_55/DeviceRegistryEvents/DeviceRegistryEvents_0.csv\"\n",
    "df = pd.read_csv(input_file, sep=\"❖\", encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "\n",
    "\n",
    "DeviceRegistryEvents_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/alphineskihouse/DeviceRegistryEvents/DeviceRegistryEvents_4.csv\"\n",
    "\n",
    "convert_double_quotes(input_file, input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-07-04 10:32:59.071770+00:00'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"TimeGenerated\"])\n",
    "df[\"TimeGenerated\"][70974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileType': 'Error'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(df.iloc[0][\"AdditionalFields\"].replace(\"'\", '\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenantId</th>\n",
       "      <th>AccountDomain</th>\n",
       "      <th>AccountName</th>\n",
       "      <th>AccountObjectId</th>\n",
       "      <th>AccountSid</th>\n",
       "      <th>AccountUpn</th>\n",
       "      <th>ActionType</th>\n",
       "      <th>AdditionalFields</th>\n",
       "      <th>AppGuardContainerId</th>\n",
       "      <th>DeviceId</th>\n",
       "      <th>...</th>\n",
       "      <th>ReportId</th>\n",
       "      <th>SHA1</th>\n",
       "      <th>SHA256</th>\n",
       "      <th>TimeGenerated</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>InitiatingProcessParentCreationTime</th>\n",
       "      <th>InitiatingProcessCreationTime</th>\n",
       "      <th>SourceSystem</th>\n",
       "      <th>Type</th>\n",
       "      <th>rn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>network service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31a048e5eea6ad6e6bc025bfa9e0e571c4c20f7e</td>\n",
       "      <td>...</td>\n",
       "      <td>12541</td>\n",
       "      <td>569bd3b531683c3de0d6ec1e4453e4cdb935de0e</td>\n",
       "      <td>2259de5b454f1af400857e03f5dfddf14f5f6b4de379ec...</td>\n",
       "      <td>2024-07-01 14:00:12.054281+00:00</td>\n",
       "      <td>2024-07-01 14:00:12.054281+00:00</td>\n",
       "      <td>2024-07-01 11:23:53.006226+00:00</td>\n",
       "      <td>2024-07-01 11:23:57.495909+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ad8cb2c434ba7527e21e95e3c648e55c27a64c0</td>\n",
       "      <td>...</td>\n",
       "      <td>132620</td>\n",
       "      <td>346dfaaf4744856c361af798122076177bf10934</td>\n",
       "      <td>f262b891058b33e63d81759a9d2f2cdd71fde9d031f4cf...</td>\n",
       "      <td>2024-07-01 14:00:20.510508+00:00</td>\n",
       "      <td>2024-07-01 14:00:20.510508+00:00</td>\n",
       "      <td>2024-06-14 04:21:18.233265+00:00</td>\n",
       "      <td>2024-06-20 02:35:12.953594+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6ad8cb2c434ba7527e21e95e3c648e55c27a64c0</td>\n",
       "      <td>...</td>\n",
       "      <td>132621</td>\n",
       "      <td>044a0cf1f6bc478a7172bf207eef1e201a18ba02</td>\n",
       "      <td>ba4038fd20e474c047be8aad5bfacdb1bfc1ddbe12f803...</td>\n",
       "      <td>2024-07-01 14:00:30.602557+00:00</td>\n",
       "      <td>2024-07-01 14:00:30.602557+00:00</td>\n",
       "      <td>2024-06-20 02:35:12.953594+00:00</td>\n",
       "      <td>2024-07-01 14:00:20.507061+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e71d36e038408014b8fe351202c5af7d0d1e4740</td>\n",
       "      <td>...</td>\n",
       "      <td>79023</td>\n",
       "      <td>b9b34e794e751a7a7f2ff32f56f63c463642e09a</td>\n",
       "      <td>aae1db57f898ca8bda18590c56f86ced6d0ead80c22033...</td>\n",
       "      <td>2024-07-01 14:00:32.067001+00:00</td>\n",
       "      <td>2024-07-01 14:00:32.067001+00:00</td>\n",
       "      <td>2024-07-01 13:03:18.956816+00:00</td>\n",
       "      <td>2024-07-01 14:00:00.786130+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e71d36e038408014b8fe351202c5af7d0d1e4740</td>\n",
       "      <td>...</td>\n",
       "      <td>79025</td>\n",
       "      <td>f93a1c1f94367e08ed7b711a1b6a773d49fceb8f</td>\n",
       "      <td>fd3ef1b4c91b2e85ccd05724a7cd527a3a27d7d549b0dc...</td>\n",
       "      <td>2024-07-01 14:00:32.631495+00:00</td>\n",
       "      <td>2024-07-01 14:00:32.631495+00:00</td>\n",
       "      <td>2024-07-01 14:00:00.786130+00:00</td>\n",
       "      <td>2024-07-01 14:00:32.031296+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41093</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>vnevado</td>\n",
       "      <td>leeg</td>\n",
       "      <td>f7202242-7b1f-4433-ba89-80e835f617f8</td>\n",
       "      <td>S-1-5-21-1840151660-3534030288-105586563-1115</td>\n",
       "      <td>leeg@vnevado.alpineskihouse.co</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d103e4d8f59b188b5e3cf0bef855d2e738f36206</td>\n",
       "      <td>...</td>\n",
       "      <td>49150</td>\n",
       "      <td>346ca2aef06b167cb8ad4f881e5512354820da66</td>\n",
       "      <td>1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...</td>\n",
       "      <td>2024-07-04 00:42:47.453129+00:00</td>\n",
       "      <td>2024-07-04 00:42:47.453129+00:00</td>\n",
       "      <td>2024-07-01 08:42:39.008313+00:00</td>\n",
       "      <td>2024-07-04 00:42:45.584720+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>41094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41094</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>vnevado</td>\n",
       "      <td>leeg</td>\n",
       "      <td>f7202242-7b1f-4433-ba89-80e835f617f8</td>\n",
       "      <td>S-1-5-21-1840151660-3534030288-105586563-1115</td>\n",
       "      <td>leeg@vnevado.alpineskihouse.co</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d103e4d8f59b188b5e3cf0bef855d2e738f36206</td>\n",
       "      <td>...</td>\n",
       "      <td>49152</td>\n",
       "      <td>346ca2aef06b167cb8ad4f881e5512354820da66</td>\n",
       "      <td>1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...</td>\n",
       "      <td>2024-07-04 00:42:47.620380+00:00</td>\n",
       "      <td>2024-07-04 00:42:47.620380+00:00</td>\n",
       "      <td>2024-07-01 08:42:39.008313+00:00</td>\n",
       "      <td>2024-07-04 00:42:45.584720+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>41095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41095</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>vnevado</td>\n",
       "      <td>leeg</td>\n",
       "      <td>f7202242-7b1f-4433-ba89-80e835f617f8</td>\n",
       "      <td>S-1-5-21-1840151660-3534030288-105586563-1115</td>\n",
       "      <td>leeg@vnevado.alpineskihouse.co</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d103e4d8f59b188b5e3cf0bef855d2e738f36206</td>\n",
       "      <td>...</td>\n",
       "      <td>49153</td>\n",
       "      <td>346ca2aef06b167cb8ad4f881e5512354820da66</td>\n",
       "      <td>1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...</td>\n",
       "      <td>2024-07-04 00:42:47.646097+00:00</td>\n",
       "      <td>2024-07-04 00:42:47.646097+00:00</td>\n",
       "      <td>2024-07-01 08:42:39.008313+00:00</td>\n",
       "      <td>2024-07-04 00:42:45.584720+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>41096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41096</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>vnevado</td>\n",
       "      <td>leeg</td>\n",
       "      <td>f7202242-7b1f-4433-ba89-80e835f617f8</td>\n",
       "      <td>S-1-5-21-1840151660-3534030288-105586563-1115</td>\n",
       "      <td>leeg@vnevado.alpineskihouse.co</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d103e4d8f59b188b5e3cf0bef855d2e738f36206</td>\n",
       "      <td>...</td>\n",
       "      <td>49166</td>\n",
       "      <td>346ca2aef06b167cb8ad4f881e5512354820da66</td>\n",
       "      <td>1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...</td>\n",
       "      <td>2024-07-04 00:42:48.377537+00:00</td>\n",
       "      <td>2024-07-04 00:42:48.377537+00:00</td>\n",
       "      <td>2024-07-01 08:42:39.008313+00:00</td>\n",
       "      <td>2024-07-04 00:42:45.584720+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>41097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41097</th>\n",
       "      <td>e34d562e-ef12-4c4e-9bc0-7c6ae357c015</td>\n",
       "      <td>nt authority</td>\n",
       "      <td>system</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S-1-5-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ProcessCreated</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d103e4d8f59b188b5e3cf0bef855d2e738f36206</td>\n",
       "      <td>...</td>\n",
       "      <td>49167</td>\n",
       "      <td>9dfb347a5b47fb90a0fd6b944ac5f27f0b142340</td>\n",
       "      <td>ca17c23bb500d1ef7c4bdf3d8d22cca181d76891440134...</td>\n",
       "      <td>2024-07-04 00:42:48.397946+00:00</td>\n",
       "      <td>2024-07-04 00:42:48.397946+00:00</td>\n",
       "      <td>2024-07-01 07:41:25.493255+00:00</td>\n",
       "      <td>2024-07-01 07:41:25.581682+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DeviceProcessEvents</td>\n",
       "      <td>41098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41098 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   TenantId AccountDomain      AccountName  \\\n",
       "0      e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority  network service   \n",
       "1      e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority           system   \n",
       "2      e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority           system   \n",
       "3      e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority           system   \n",
       "4      e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority           system   \n",
       "...                                     ...           ...              ...   \n",
       "41093  e34d562e-ef12-4c4e-9bc0-7c6ae357c015       vnevado             leeg   \n",
       "41094  e34d562e-ef12-4c4e-9bc0-7c6ae357c015       vnevado             leeg   \n",
       "41095  e34d562e-ef12-4c4e-9bc0-7c6ae357c015       vnevado             leeg   \n",
       "41096  e34d562e-ef12-4c4e-9bc0-7c6ae357c015       vnevado             leeg   \n",
       "41097  e34d562e-ef12-4c4e-9bc0-7c6ae357c015  nt authority           system   \n",
       "\n",
       "                            AccountObjectId  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "41093  f7202242-7b1f-4433-ba89-80e835f617f8   \n",
       "41094  f7202242-7b1f-4433-ba89-80e835f617f8   \n",
       "41095  f7202242-7b1f-4433-ba89-80e835f617f8   \n",
       "41096  f7202242-7b1f-4433-ba89-80e835f617f8   \n",
       "41097                                   NaN   \n",
       "\n",
       "                                          AccountSid  \\\n",
       "0                                           S-1-5-20   \n",
       "1                                           S-1-5-18   \n",
       "2                                           S-1-5-18   \n",
       "3                                           S-1-5-18   \n",
       "4                                           S-1-5-18   \n",
       "...                                              ...   \n",
       "41093  S-1-5-21-1840151660-3534030288-105586563-1115   \n",
       "41094  S-1-5-21-1840151660-3534030288-105586563-1115   \n",
       "41095  S-1-5-21-1840151660-3534030288-105586563-1115   \n",
       "41096  S-1-5-21-1840151660-3534030288-105586563-1115   \n",
       "41097                                       S-1-5-18   \n",
       "\n",
       "                           AccountUpn      ActionType AdditionalFields  \\\n",
       "0                                 NaN  ProcessCreated               {}   \n",
       "1                                 NaN  ProcessCreated               {}   \n",
       "2                                 NaN  ProcessCreated               {}   \n",
       "3                                 NaN  ProcessCreated               {}   \n",
       "4                                 NaN  ProcessCreated               {}   \n",
       "...                               ...             ...              ...   \n",
       "41093  leeg@vnevado.alpineskihouse.co  ProcessCreated               {}   \n",
       "41094  leeg@vnevado.alpineskihouse.co  ProcessCreated               {}   \n",
       "41095  leeg@vnevado.alpineskihouse.co  ProcessCreated               {}   \n",
       "41096  leeg@vnevado.alpineskihouse.co  ProcessCreated               {}   \n",
       "41097                             NaN  ProcessCreated               {}   \n",
       "\n",
       "       AppGuardContainerId                                  DeviceId  ...  \\\n",
       "0                      NaN  31a048e5eea6ad6e6bc025bfa9e0e571c4c20f7e  ...   \n",
       "1                      NaN  6ad8cb2c434ba7527e21e95e3c648e55c27a64c0  ...   \n",
       "2                      NaN  6ad8cb2c434ba7527e21e95e3c648e55c27a64c0  ...   \n",
       "3                      NaN  e71d36e038408014b8fe351202c5af7d0d1e4740  ...   \n",
       "4                      NaN  e71d36e038408014b8fe351202c5af7d0d1e4740  ...   \n",
       "...                    ...                                       ...  ...   \n",
       "41093                  NaN  d103e4d8f59b188b5e3cf0bef855d2e738f36206  ...   \n",
       "41094                  NaN  d103e4d8f59b188b5e3cf0bef855d2e738f36206  ...   \n",
       "41095                  NaN  d103e4d8f59b188b5e3cf0bef855d2e738f36206  ...   \n",
       "41096                  NaN  d103e4d8f59b188b5e3cf0bef855d2e738f36206  ...   \n",
       "41097                  NaN  d103e4d8f59b188b5e3cf0bef855d2e738f36206  ...   \n",
       "\n",
       "      ReportId                                      SHA1  \\\n",
       "0        12541  569bd3b531683c3de0d6ec1e4453e4cdb935de0e   \n",
       "1       132620  346dfaaf4744856c361af798122076177bf10934   \n",
       "2       132621  044a0cf1f6bc478a7172bf207eef1e201a18ba02   \n",
       "3        79023  b9b34e794e751a7a7f2ff32f56f63c463642e09a   \n",
       "4        79025  f93a1c1f94367e08ed7b711a1b6a773d49fceb8f   \n",
       "...        ...                                       ...   \n",
       "41093    49150  346ca2aef06b167cb8ad4f881e5512354820da66   \n",
       "41094    49152  346ca2aef06b167cb8ad4f881e5512354820da66   \n",
       "41095    49153  346ca2aef06b167cb8ad4f881e5512354820da66   \n",
       "41096    49166  346ca2aef06b167cb8ad4f881e5512354820da66   \n",
       "41097    49167  9dfb347a5b47fb90a0fd6b944ac5f27f0b142340   \n",
       "\n",
       "                                                  SHA256  \\\n",
       "0      2259de5b454f1af400857e03f5dfddf14f5f6b4de379ec...   \n",
       "1      f262b891058b33e63d81759a9d2f2cdd71fde9d031f4cf...   \n",
       "2      ba4038fd20e474c047be8aad5bfacdb1bfc1ddbe12f803...   \n",
       "3      aae1db57f898ca8bda18590c56f86ced6d0ead80c22033...   \n",
       "4      fd3ef1b4c91b2e85ccd05724a7cd527a3a27d7d549b0dc...   \n",
       "...                                                  ...   \n",
       "41093  1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...   \n",
       "41094  1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...   \n",
       "41095  1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...   \n",
       "41096  1ff2a3bac3ea1d70945eb8ed497d4e86b9b583f4f2d59b...   \n",
       "41097  ca17c23bb500d1ef7c4bdf3d8d22cca181d76891440134...   \n",
       "\n",
       "                          TimeGenerated                         Timestamp  \\\n",
       "0      2024-07-01 14:00:12.054281+00:00  2024-07-01 14:00:12.054281+00:00   \n",
       "1      2024-07-01 14:00:20.510508+00:00  2024-07-01 14:00:20.510508+00:00   \n",
       "2      2024-07-01 14:00:30.602557+00:00  2024-07-01 14:00:30.602557+00:00   \n",
       "3      2024-07-01 14:00:32.067001+00:00  2024-07-01 14:00:32.067001+00:00   \n",
       "4      2024-07-01 14:00:32.631495+00:00  2024-07-01 14:00:32.631495+00:00   \n",
       "...                                 ...                               ...   \n",
       "41093  2024-07-04 00:42:47.453129+00:00  2024-07-04 00:42:47.453129+00:00   \n",
       "41094  2024-07-04 00:42:47.620380+00:00  2024-07-04 00:42:47.620380+00:00   \n",
       "41095  2024-07-04 00:42:47.646097+00:00  2024-07-04 00:42:47.646097+00:00   \n",
       "41096  2024-07-04 00:42:48.377537+00:00  2024-07-04 00:42:48.377537+00:00   \n",
       "41097  2024-07-04 00:42:48.397946+00:00  2024-07-04 00:42:48.397946+00:00   \n",
       "\n",
       "      InitiatingProcessParentCreationTime     InitiatingProcessCreationTime  \\\n",
       "0        2024-07-01 11:23:53.006226+00:00  2024-07-01 11:23:57.495909+00:00   \n",
       "1        2024-06-14 04:21:18.233265+00:00  2024-06-20 02:35:12.953594+00:00   \n",
       "2        2024-06-20 02:35:12.953594+00:00  2024-07-01 14:00:20.507061+00:00   \n",
       "3        2024-07-01 13:03:18.956816+00:00  2024-07-01 14:00:00.786130+00:00   \n",
       "4        2024-07-01 14:00:00.786130+00:00  2024-07-01 14:00:32.031296+00:00   \n",
       "...                                   ...                               ...   \n",
       "41093    2024-07-01 08:42:39.008313+00:00  2024-07-04 00:42:45.584720+00:00   \n",
       "41094    2024-07-01 08:42:39.008313+00:00  2024-07-04 00:42:45.584720+00:00   \n",
       "41095    2024-07-01 08:42:39.008313+00:00  2024-07-04 00:42:45.584720+00:00   \n",
       "41096    2024-07-01 08:42:39.008313+00:00  2024-07-04 00:42:45.584720+00:00   \n",
       "41097    2024-07-01 07:41:25.493255+00:00  2024-07-01 07:41:25.581682+00:00   \n",
       "\n",
       "      SourceSystem                 Type     rn  \n",
       "0              NaN  DeviceProcessEvents      1  \n",
       "1              NaN  DeviceProcessEvents      2  \n",
       "2              NaN  DeviceProcessEvents      3  \n",
       "3              NaN  DeviceProcessEvents      4  \n",
       "4              NaN  DeviceProcessEvents      5  \n",
       "...            ...                  ...    ...  \n",
       "41093          NaN  DeviceProcessEvents  41094  \n",
       "41094          NaN  DeviceProcessEvents  41095  \n",
       "41095          NaN  DeviceProcessEvents  41096  \n",
       "41096          NaN  DeviceProcessEvents  41097  \n",
       "41097          NaN  DeviceProcessEvents  41098  \n",
       "\n",
       "[41098 rows x 64 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# \n",
    "# basefolder = \"./data/alphineskihouse\"\n",
    "basefolder = \"data/incidents/incident_55\"\n",
    "file = \"DeviceProcessEvents/DeviceProcessEvents_0.csv\"\n",
    "# metafile = \"UrlClickEvents.meta\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(basefolder, file), sep=\"❖\", encoding='utf-8-sig', on_bad_lines='skip', engine='python')\n",
    "print(len(df.columns))\n",
    "\n",
    "# save with another separator\n",
    "# df.to_csv(os.path.join(basefolder, file), sep=\"❖\", encoding='utf-8-sig', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenantId                               e34d562e-ef12-4c4e-9bc0-7c6ae357c015\n",
       "AccountDomain                                                  nt authority\n",
       "AccountName                                                          system\n",
       "AccountObjectId                                                         NaN\n",
       "AccountSid                                                         S-1-5-18\n",
       "                                                       ...                 \n",
       "InitiatingProcessParentCreationTime        2024-07-01 11:23:53.006226+00:00\n",
       "InitiatingProcessCreationTime              2024-07-01 11:23:57.347732+00:00\n",
       "SourceSystem                                                            NaN\n",
       "Type                                                    DeviceProcessEvents\n",
       "rn                                                                      365\n",
       "Name: 364, Length: 64, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(basefolder, metafile), 'r') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(len(meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import timedelta, datetime, timezone\n",
    "from azure.monitor.query import LogsQueryClient, LogsQueryStatus\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Optional, Union, Tuple\n",
    "from textwrap import dedent\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "client = LogsQueryClient(credential)\n",
    "def get_count(\n",
    "        workspace_id: str,\n",
    "        table_name: str,\n",
    "        timpespan: Optional[Union[timedelta, Tuple[datetime, timedelta], Tuple[datetime, datetime]]]\n",
    "    ) -> int:\n",
    "\n",
    "    response = client.query_workspace(workspace_id, f\"{table_name} | count\", timespan=timpespan)\n",
    "\n",
    "    if response.status == LogsQueryStatus.SUCCESS:\n",
    "        return response.tables[0].rows[0][0]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def calculate_size_per_entry(\n",
    "        workspace_id: str,\n",
    "        table_name: str,\n",
    "        timpespan: Optional[Union[timedelta, Tuple[datetime, timedelta], Tuple[datetime, datetime]]]\n",
    "    ) -> int:\n",
    "\n",
    "    response = client.query_workspace(workspace_id, f\"{table_name} | limit 2000\", timespan=timpespan, include_statistics=True)\n",
    "    if response.status == LogsQueryStatus.SUCCESS:\n",
    "        if  response.statistics['query']['datasetStatistics'][0]['tableRowCount'] == 0:\n",
    "            print(f\"Table {table_name} is empty.\")\n",
    "            return 0\n",
    "        return response.statistics['query']['datasetStatistics'][0]['tableSize'] / response.statistics['query']['datasetStatistics'][0]['tableRowCount']\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def check_segemented_query(\n",
    "        workspace_id: str,\n",
    "        table_name: str,\n",
    "        timespan: Optional[Union[timedelta, Tuple[datetime, timedelta], Tuple[datetime, datetime]]],\n",
    "        max_size_allowed: int = 60000000, # in bytes, ~60MB\n",
    "        max_count_allowed: int = 500000,\n",
    "        verbose: bool = False\n",
    "    ) -> Tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    Check if the query need to be segmented or not\n",
    "    \n",
    "    Args:\n",
    "    - workspace_id: Azure Log Analytics workspace id\n",
    "    - table_name: table name to query\n",
    "    - timespan: time range to query\n",
    "    - max_size_allowed: maximum size allowed for a single query\n",
    "    - max_count_allowed: maximum count allowed for a single query\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[bool, int, int, int]:\n",
    "        - bool: if the query need to be segmented or not\n",
    "        - int: number of row per query\n",
    "        - int: total count of the table\n",
    "        - int: total size of the table, in bytes\n",
    "    \"\"\"\n",
    "    # https://learn.microsoft.com/en-us/azure/azure-monitor/service-limits#la-query-api\n",
    "\n",
    "    total_count = get_count(workspace_id, table_name, timespan)\n",
    "    size_per_entry = calculate_size_per_entry(workspace_id, table_name, timespan)\n",
    "    if total_count == -1 or size_per_entry == -1:\n",
    "        return True, 0, -1, -1\n",
    "    total_size = total_count * size_per_entry \n",
    "    if total_size < max_size_allowed and total_count < max_count_allowed:\n",
    "        if verbose:\n",
    "            print(f\"Total count: {total_count}\", f\"Size per entry: {size_per_entry}\", f\"Total size: {total_size/1024/1024} MB\")\n",
    "        return False, -1, total_count, total_size\n",
    "    \n",
    "    row_per_query = max_count_allowed\n",
    "    if total_size > max_size_allowed:\n",
    "        # get number of row per query \n",
    "        row_per_query = min(row_per_query, max_size_allowed // size_per_entry)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Table: {table_name}\", \n",
    "              f\"Total count: {total_count}\", \n",
    "              f\"Size per entry: {size_per_entry} Bytes\", \n",
    "              f\"Total size: {total_size/1024/1024} MB\", \n",
    "              f\"Row per query: {row_per_query}\", \n",
    "              f\"Estimate table count: {total_count // row_per_query}\",\n",
    "              sep=\", \",\n",
    "              )\n",
    "    return True, int(row_per_query), total_count, total_size\n",
    "\n",
    "def query_and_save_data(\n",
    "        workspace_id: str,\n",
    "        table_name: str,\n",
    "        timespan: Optional[Union[timedelta, Tuple[datetime, timedelta], Tuple[datetime, datetime]]],\n",
    "        file_path: str,\n",
    "        verbose: bool = False\n",
    "):\n",
    "    \n",
    "    def save_table(file_path_name, response, need_metadata=False):\n",
    "        table = response.tables[0]\n",
    "        df = pd.DataFrame(data=table.rows, columns=table.columns)\n",
    "        if len(df) == 0:\n",
    "            print(f\"Table {table_name} is empty. Skipping.\")\n",
    "            return -1, -1\n",
    "        metadata = dict(zip(df.columns.tolist(), table.columns_types))\n",
    "        if need_metadata:\n",
    "            with open(file_path_name.replace(\".csv\", \"_metadata.json\"), \"w\") as f:\n",
    "                json.dump(metadata, f)\n",
    "\n",
    "        json_columns = [col for col, dtype in metadata.items() if dtype == \"dynamic\"]\n",
    "        for column in json_columns:\n",
    "            df[column] = df[column].apply(lambda x: \"{}\" if x == \"\" else x)\n",
    "            df[column] = df[column].apply(lambda x: \"{}\" if pd.isnull(x) else x)\n",
    "        \n",
    "        df.to_csv(file_path_name, index=False, sep=\"¤\", encoding='utf-8')\n",
    "        return df[\"TimeGenerated\"].min(), df[\"TimeGenerated\"].max()\n",
    "    \n",
    "    max_size_allowed: int = 60000000\n",
    "    need_segement, row_per_query, total_count, total_size = check_segemented_query(workspace_id, table_name, timespan, verbose=verbose, max_size_allowed=max_size_allowed)\n",
    "\n",
    "    if need_segement:\n",
    "        updated_file_path = os.path.join(file_path, table_name)\n",
    "        os.makedirs(updated_file_path, exist_ok=True)\n",
    "        \n",
    "        # get total time range in hours, conver to start and end time\n",
    "        if isinstance(timespan, timedelta):\n",
    "            timespan = (datetime.utcnow() - timespan, datetime.utcnow())\n",
    "        elif isinstance(timespan[1], timedelta):\n",
    "            total_hours = timespan[1].total_seconds() / 3600\n",
    "            timespan = (timespan[0], timespan[0] + timespan[1])\n",
    "        else:\n",
    "            total_hours = (timespan[1] - timespan[0]).total_seconds() / 3600\n",
    "        \n",
    "        # print(type(timespan[0]))\n",
    "        # get size per hour\n",
    "        size_per_hour = total_size / total_hours\n",
    "        # approximate 200MB per time chunk\n",
    "        time_chunk = int(200 * 1024 * 1024 / size_per_hour)\n",
    "        print(f\"Time chunk: {time_chunk} hours\")\n",
    "\n",
    "        tmp_start_time = timespan[0]\n",
    "        chunk_id = 0\n",
    "        # if table_name == \"AADNonInteractiveUserSignInLogs\":\n",
    "        #     # 2024-07-15 13:02:04.923788+00:00\n",
    "        #     tmp_start_time = datetime(2024, 7, 15, 13, 2, 4, 923788, tzinfo=timezone.utc) + timedelta(milliseconds=1)\n",
    "        #     chunk_id = 44\n",
    "        #     print(f\"Resuming from chunk 44, {tmp_start_time}\")\n",
    "        query_template = dedent(\"\"\"{table_name} \n",
    "| order by TimeGenerated asc\n",
    "| serialize\n",
    "| extend rn = row_number() \n",
    "| where rn <= {end}\n",
    "\"\"\")        \n",
    "        while tmp_start_time < timespan[1]:\n",
    "            # get data from a time chunk\n",
    "            tmp_timespan = (tmp_start_time, min(tmp_start_time + timedelta(hours=time_chunk), timespan[1]))\n",
    "\n",
    "            response = client.query_workspace(\n",
    "                workspace_id, \n",
    "                query_template.format(table_name=table_name, end=row_per_query),\n",
    "                timespan=tmp_timespan\n",
    "            ) # only return the first row_per_query rows\n",
    "    \n",
    "            if response.status != LogsQueryStatus.SUCCESS:\n",
    "                error = response.partial_error\n",
    "                print(f\"Getting error, retry chunk {chunk_id}\", error)\n",
    "                # update max size allowed and row per query\n",
    "                max_size_allowed -= 2000000\n",
    "                row_per_query = min(row_per_query, max_size_allowed // (total_size/total_count))\n",
    "            else:\n",
    "                # set new start time to be the last time from the response\n",
    "                earliest, latest = save_table(os.path.join(updated_file_path, f\"{table_name}_{chunk_id}.csv\"), response, need_metadata=chunk_id == 0)\n",
    "                if earliest == -1:\n",
    "                    print(f\"Reached end of the table. Exiting.\")\n",
    "                    break\n",
    "                # from pd timestamp to datetime.datetime, and +1 in milliseconds\n",
    "                tmp_start_time = latest.to_pydatetime() + timedelta(milliseconds=1)\n",
    "                chunk_id += 1\n",
    "                print(f\"Chunk {chunk_id}: {earliest} - {latest}\")  #Required span: {tmp_timespan} || Actual:\n",
    "            \n",
    "    else:\n",
    "        response = client.query_workspace(workspace_id, f\"{table_name}\", timespan=timespan)\n",
    "        save_table(os.path.join(file_path, f\"{table_name}.csv\"), response, need_metadata=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # # number of queries to run\n",
    "        # query_count = int(total_count // row_per_query) + 1\n",
    "\n",
    "        # for i in range(query_count):\n",
    "        #     start = i * row_per_query\n",
    "        #     end = min((i + 1) * row_per_query, total_count)\n",
    "        #     query = query_template.format(table_name=table_name, start=start, end=end)\n",
    "        #     response = client.query_workspace(workspace_id, query, timespan=timespan)\n",
    "\n",
    "        #     if response.status != LogsQueryStatus.SUCCESS:\n",
    "        #         error = response.partial_error\n",
    "        #         data = response.partial_data\n",
    "        #         print(error)\n",
    "        #         raise HttpResponseError(response.error)\n",
    "\n",
    "        #     save_table(os.path.join(updated_file_path, f\"{table_name}_{i}.csv\"), response, need_metadata=i==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table AADManagedIdentitySignInLogs has 24516 rows and 12.774 MB   (GB: 0.012)\n",
      "Table AADNonInteractiveUserSignInLogs has 1627812 rows and 7060.33 MB   (GB: 6.895)\n",
      "Table AADProvisioningLogs has 635 rows and 1.582 MB   (GB: 0.002)\n",
      "Table AADRiskyUsers has 175 rows and 0.034 MB   (GB: 0.0)\n",
      "Table AADServicePrincipalSignInLogs has 190271 rows and 146.289 MB   (GB: 0.143)\n",
      "Table AADUserRiskEvents has 336 rows and 0.296 MB   (GB: 0.0)\n",
      "Table Alert has 16 rows and 0.022 MB   (GB: 0.0)\n",
      "Table AmlDataLabelEvent has 1 rows and 0.0 MB   (GB: 0.0)\n",
      "Table AmlDataStoreEvent has 12 rows and 0.005 MB   (GB: 0.0)\n",
      "Table AuditLogs has 73633 rows and 137.771 MB   (GB: 0.135)\n",
      "Table AZFWApplicationRule has 222692 rows and 72.146 MB   (GB: 0.07)\n",
      "Table AZFWApplicationRuleAggregation has 49038 rows and 17.156 MB   (GB: 0.017)\n",
      "Table AZFWDnsQuery has 461803 rows and 130.201 MB   (GB: 0.127)\n",
      "Table AZFWFlowTrace has 86824 rows and 21.609 MB   (GB: 0.021)\n",
      "Table AZFWIdpsSignature has 8221 rows and 2.49 MB   (GB: 0.002)\n",
      "Table AZFWNatRule has 37717 rows and 11.69 MB   (GB: 0.011)\n",
      "Table AZFWNatRuleAggregation has 13407 rows and 4.068 MB   (GB: 0.004)\n",
      "Table AZFWNetworkRule has 56758 rows and 13.801 MB   (GB: 0.013)\n",
      "Table AZFWNetworkRuleAggregation has 2908 rows and 0.748 MB   (GB: 0.001)\n",
      "Table AZFWThreatIntel has 2200 rows and 0.611 MB   (GB: 0.001)\n",
      "Table AzureActivity has 1664 rows and 10.577 MB   (GB: 0.01)\n",
      "Table AzureMetrics has 3730824 rows and 1910.559 MB   (GB: 1.866)\n",
      "Table ContainerRegistryRepositoryEvents has 7 rows and 0.005 MB   (GB: 0.0)\n",
      "Table Heartbeat has 64787 rows and 44.322 MB   (GB: 0.043)\n",
      "Table IntuneAuditLogs has 122 rows and 0.238 MB   (GB: 0.0)\n",
      "Table IntuneDeviceComplianceOrg has 573 rows and 0.239 MB   (GB: 0.0)\n",
      "Table IntuneDevices has 573 rows and 0.349 MB   (GB: 0.0)\n",
      "Table IntuneOperationalLogs has 18 rows and 0.018 MB   (GB: 0.0)\n",
      "Table LAQueryLogs has 76828 rows and 198.798 MB   (GB: 0.194)\n",
      "Table LASummaryLogs has 36 rows and 0.009 MB   (GB: 0.0)\n",
      "Table MicrosoftAzureBastionAuditLogs has 679 rows and 0.439 MB   (GB: 0.0)\n",
      "Table MicrosoftGraphActivityLogs has 2065547 rows and 1965.194 MB   (GB: 1.919)\n",
      "Table NetworkAccessTraffic is empty.\n",
      "Table NetworkAccessTraffic has 0 rows and 0.0 MB   (GB: 0.0)\n",
      "Table Operation has 49 rows and 0.007 MB   (GB: 0.0)\n",
      "Table SigninLogs has 156454 rows and 804.006 MB   (GB: 0.785)\n",
      "Table Usage has 48949 rows and 19.314 MB   (GB: 0.019)\n",
      "Table Windows365AuditLogs has 4 rows and 0.007 MB   (GB: 0.0)\n",
      "Table AlertEvidence has 9869 rows and 14.703 MB   (GB: 0.014)\n",
      "Table AlertInfo has 951 rows and 0.214 MB   (GB: 0.0)\n",
      "Table Anomalies has 40 rows and 0.161 MB   (GB: 0.0)\n",
      "Table CloudAppEvents has 462039 rows and 817.642 MB   (GB: 0.798)\n",
      "Table DeviceEvents has 896895 rows and 980.08 MB   (GB: 0.957)\n",
      "Table DeviceFileCertificateInfo has 137227 rows and 67.341 MB   (GB: 0.066)\n",
      "Table DeviceFileEvents has 1029974 rows and 2451.239 MB   (GB: 2.394)\n",
      "Table DeviceImageLoadEvents has 143052 rows and 158.57 MB   (GB: 0.155)\n",
      "Table DeviceInfo has 20252 rows and 8.63 MB   (GB: 0.008)\n",
      "Table DeviceLogonEvents has 60276 rows and 35.267 MB   (GB: 0.034)\n",
      "Table DeviceNetworkEvents has 908779 rows and 535.267 MB   (GB: 0.523)\n",
      "Table DeviceNetworkInfo has 84619 rows and 28.522 MB   (GB: 0.028)\n",
      "Table DeviceProcessEvents has 1193749 rows and 2657.654 MB   (GB: 2.595)\n",
      "Table DeviceRegistryEvents has 940188 rows and 757.447 MB   (GB: 0.74)\n",
      "Table EmailAttachmentInfo has 15328 rows and 7.103 MB   (GB: 0.007)\n",
      "Table EmailEvents has 17727 rows and 9.943 MB   (GB: 0.01)\n",
      "Table EmailPostDeliveryEvents has 17 rows and 0.006 MB   (GB: 0.0)\n",
      "Table EmailUrlInfo has 20207 rows and 6.316 MB   (GB: 0.006)\n",
      "Table HuntingBookmark has 8 rows and 0.022 MB   (GB: 0.0)\n",
      "Table IdentityDirectoryEvents has 806 rows and 0.404 MB   (GB: 0.0)\n",
      "Table IdentityLogonEvents has 176520 rows and 89.089 MB   (GB: 0.087)\n",
      "Table IdentityQueryEvents has 31459 rows and 35.954 MB   (GB: 0.035)\n",
      "Table OfficeActivity has 39043 rows and 49.155 MB   (GB: 0.048)\n",
      "Table SecurityAlert has 14804 rows and 103.229 MB   (GB: 0.101)\n",
      "Table SecurityIncident has 1085 rows and 1.534 MB   (GB: 0.001)\n",
      "Table SentinelAudit has 21 rows and 0.102 MB   (GB: 0.0)\n",
      "Table SentinelHealth has 7934 rows and 7.569 MB   (GB: 0.007)\n",
      "Table ThreatIntelligenceIndicator has 2878437 rows and 1360.743 MB   (GB: 1.329)\n",
      "Table UrlClickEvents has 26 rows and 0.009 MB   (GB: 0.0)\n",
      "Table Watchlist has 1581 rows and 1.263 MB   (GB: 0.001)\n",
      "Total size: 22772.884 MB   (GB: 22.239)\n"
     ]
    }
   ],
   "source": [
    "ATEVET_17 = \"0fbd2874-9307-4572-b499-f8fa3cc75daf\"\n",
    "Alpine = \"e34d562e-ef12-4c4e-9bc0-7c6ae357c015\"\n",
    "# 45 days\n",
    "start_time = datetime(2024, 6, 18, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "end_time = datetime(2024, 8, 2, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "# for 3 hours\n",
    "duration = timedelta(hours=3)\n",
    "# end_time = start_time + duration\n",
    "\n",
    "from download_logs import LIST_TABLES\n",
    "# # print table size of each table and total size\n",
    "total_size = 0\n",
    "for table in LIST_TABLES:\n",
    "    need_segement, row_per_query, total_count, total_size_table = check_segemented_query(Alpine, table, (start_time, end_time))\n",
    "    \n",
    "    if total_count == -1 or total_size_table == -1:\n",
    "        print(f\"Table {table} is failed to get size.\")\n",
    "        continue\n",
    "\n",
    "    total_size += total_size_table\n",
    "    print(f\"Table {table} has {total_count} rows and {round(total_size_table/1024/1024, 3)} MB   (GB: {round(total_size_table/1024/1024/1024, 3)})\")\n",
    "\n",
    "print(f\"Total size: {round(total_size/1024/1024, 3)} MB   (GB: {round(total_size/1024/1024/1024, 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-18 00:01:18.645615+00:00\n",
      "2024-06-18 00:01:18.645616+00:00\n",
      "2024-06-18 00:01:18.646615+00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Your datetime string\n",
    "datetime_str = \"2024-06-18 00:01:18.645615+00:00\"\n",
    "\n",
    "# Convert the string to a datetime object\n",
    "dt_obj = datetime.fromisoformat(datetime_str)\n",
    "\n",
    "# Print the datetime object\n",
    "print(dt_obj)\n",
    "print(dt_obj+timedelta(microseconds=1))\n",
    "print(dt_obj+timedelta(milliseconds=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table AADManagedIdentitySignInLogs is already saved.\n",
      "Table AADNonInteractiveUserSignInLogs is already saved.\n",
      "Table AADProvisioningLogs is already saved.\n",
      "Table AADRiskyUsers is already saved.\n",
      "Table AADServicePrincipalSignInLogs is already saved.\n",
      "Table AADUserRiskEvents is already saved.\n",
      "Table Alert is already saved.\n",
      "Table AmlDataLabelEvent is already saved.\n",
      "Table AmlDataStoreEvent is already saved.\n",
      "Table AuditLogs is already saved.\n",
      "Table AZFWApplicationRule is already saved.\n",
      "Table AZFWApplicationRuleAggregation is already saved.\n",
      "Table AZFWDnsQuery is already saved.\n",
      "Table AZFWFlowTrace is already saved.\n",
      "Table AZFWIdpsSignature is already saved.\n",
      "Table AZFWNatRule is already saved.\n",
      "Table AZFWNatRuleAggregation is already saved.\n",
      "Table AZFWNetworkRule is already saved.\n",
      "Table AZFWNetworkRuleAggregation is already saved.\n",
      "Table AZFWThreatIntel is already saved.\n",
      "Table AzureActivity is already saved.\n",
      "Table AzureMetrics is already saved.\n",
      "Table ContainerRegistryRepositoryEvents is already saved.\n",
      "Table Heartbeat is already saved.\n",
      "Table IntuneAuditLogs is already saved.\n",
      "Table IntuneDeviceComplianceOrg is already saved.\n",
      "Table IntuneDevices is already saved.\n",
      "Table IntuneOperationalLogs is already saved.\n",
      "Table LAQueryLogs is already saved.\n",
      "Table LASummaryLogs is already saved.\n",
      "Table MicrosoftAzureBastionAuditLogs is already saved.\n",
      "Table MicrosoftGraphActivityLogs is already saved.\n",
      "Table NetworkAccessTraffic is empty.\n",
      "Total count: 0 Size per entry: 0 Total size: 0.0 MB\n",
      "Table NetworkAccessTraffic is empty. Skipping.\n",
      "Table NetworkAccessTraffic is saved.\n",
      "Table Operation is already saved.\n",
      "Table SigninLogs is already saved.\n",
      "Table Usage is already saved.\n",
      "Table Windows365AuditLogs is already saved.\n",
      "Table AlertEvidence is already saved.\n",
      "Table AlertInfo is already saved.\n",
      "Table Anomalies is already saved.\n",
      "Table CloudAppEvents is already saved.\n",
      "Table DeviceEvents is already saved.\n",
      "Table DeviceFileCertificateInfo is already saved.\n",
      "Table DeviceFileEvents is already saved.\n",
      "Table DeviceImageLoadEvents is already saved.\n",
      "Table DeviceInfo is already saved.\n",
      "Table DeviceLogonEvents is already saved.\n",
      "Table DeviceNetworkEvents is already saved.\n",
      "Table DeviceNetworkInfo is already saved.\n",
      "Table DeviceProcessEvents is already saved.\n",
      "Table DeviceRegistryEvents is already saved.\n",
      "Table EmailAttachmentInfo is already saved.\n",
      "Table EmailEvents is already saved.\n",
      "Table EmailPostDeliveryEvents is already saved.\n",
      "Table EmailUrlInfo is already saved.\n",
      "Table HuntingBookmark is already saved.\n",
      "Table IdentityDirectoryEvents is already saved.\n",
      "Table IdentityLogonEvents is already saved.\n",
      "Table IdentityQueryEvents is already saved.\n",
      "Table OfficeActivity is already saved.\n",
      "Table SecurityAlert is already saved.\n",
      "Table SecurityIncident is already saved.\n",
      "Table SentinelAudit is already saved.\n",
      "Table SentinelHealth is already saved.\n",
      "Table: ThreatIntelligenceIndicator, Total count: 2878437, Size per entry: 479.313 Bytes, Total size: 1315.7580125627517 MB, Row per query: 125179.0, Estimate table count: 22.0\n",
      "Time chunk: 164 hours\n",
      "Getting error, retry chunk 0 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Chunk 1: 2024-06-18 00:00:00.013194+00:00 - 2024-06-19 13:30:12.511590+00:00\n",
      "Chunk 2: 2024-06-19 13:30:13.024253+00:00 - 2024-06-21 00:39:27.535038+00:00\n",
      "Chunk 3: 2024-06-21 00:39:28.861722+00:00 - 2024-06-22 15:05:51.937167+00:00\n",
      "Chunk 4: 2024-06-22 15:05:51.938287+00:00 - 2024-06-24 03:05:34.354059+00:00\n",
      "Chunk 5: 2024-06-24 03:05:35.064055+00:00 - 2024-06-25 15:05:31.046830+00:00\n",
      "Chunk 6: 2024-06-25 15:05:31.147777+00:00 - 2024-06-27 04:37:55.809938+00:00\n",
      "Chunk 7: 2024-06-27 04:37:55.931611+00:00 - 2024-06-28 23:28:43.999863+00:00\n",
      "Getting error, retry chunk 7 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Chunk 8: 2024-06-28 23:28:44.160313+00:00 - 2024-06-30 15:48:55.294829+00:00\n",
      "Chunk 9: 2024-06-30 15:48:56.155740+00:00 - 2024-07-02 09:10:21.091870+00:00\n",
      "Chunk 10: 2024-07-02 09:10:24.162031+00:00 - 2024-07-04 05:36:23.195997+00:00\n",
      "Chunk 11: 2024-07-04 05:36:23.529176+00:00 - 2024-07-06 04:18:16.996092+00:00\n",
      "Chunk 12: 2024-07-06 04:18:17.049435+00:00 - 2024-07-08 03:02:32.710951+00:00\n",
      "Chunk 13: 2024-07-08 03:02:34.344025+00:00 - 2024-07-10 10:47:54.445930+00:00\n",
      "Chunk 14: 2024-07-10 10:47:54.464195+00:00 - 2024-07-12 17:04:52.355912+00:00\n",
      "Chunk 15: 2024-07-12 17:04:53.336690+00:00 - 2024-07-14 14:31:15.338871+00:00\n",
      "Chunk 16: 2024-07-14 14:31:15.406840+00:00 - 2024-07-16 15:20:39.881362+00:00\n",
      "Chunk 17: 2024-07-16 15:20:39.882112+00:00 - 2024-07-18 15:31:06.520796+00:00\n",
      "Chunk 18: 2024-07-18 15:31:06.521134+00:00 - 2024-07-19 16:40:15.659521+00:00\n",
      "Getting error, retry chunk 18 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Chunk 19: 2024-07-19 16:40:17.020482+00:00 - 2024-07-20 07:47:09.532309+00:00\n",
      "Getting error, retry chunk 19 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Getting error, retry chunk 19 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Getting error, retry chunk 19 {'code': 'PartialError', 'message': 'There were some errors when processing your query.', 'details': [{'code': 'EngineError', 'message': 'Something went wrong processing your query on the server.', 'innererror': {'code': '-2133196797', 'message': 'The results of this query exceed the set limit of 64000000 bytes, so not all records were returned (E_QUERY_RESULT_SET_TOO_LARGE, 0x80DA0003). See https://aka.ms/kustoquerylimits for more information and possible solutions.', 'severity': 2, 'severityName': 'Error'}}], 'status': <LogsQueryStatus.FAILURE: 'Failure'>}\n",
      "Chunk 20: 2024-07-20 07:47:09.912234+00:00 - 2024-07-21 11:23:31.391461+00:00\n",
      "Chunk 21: 2024-07-21 11:23:34.161050+00:00 - 2024-07-23 09:47:18.557864+00:00\n",
      "Chunk 22: 2024-07-23 09:47:21.803643+00:00 - 2024-07-25 15:30:11.069301+00:00\n",
      "Chunk 23: 2024-07-25 15:30:11.805915+00:00 - 2024-07-27 16:31:00.813589+00:00\n",
      "Chunk 24: 2024-07-27 16:31:00.814219+00:00 - 2024-07-29 17:22:00.460678+00:00\n",
      "Chunk 25: 2024-07-29 17:22:00.474997+00:00 - 2024-08-01 06:03:17.512731+00:00\n",
      "Chunk 26: 2024-08-01 06:03:17.791634+00:00 - 2024-08-01 23:59:47.541732+00:00\n",
      "Table ThreatIntelligenceIndicator is empty. Skipping.\n",
      "Reached end of the table. Exiting.\n",
      "Table ThreatIntelligenceIndicator is saved.\n",
      "Table UrlClickEvents is already saved.\n",
      "Table Watchlist is already saved.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/alpineSkiHouse\"\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "for table in LIST_TABLES:\n",
    "    if os.path.exists(os.path.join(file_path, f\"{table}.csv\")) or os.path.exists(os.path.join(file_path, table)):\n",
    "        print(f\"Table {table} is already saved.\")\n",
    "        continue\n",
    "    try :\n",
    "        query_and_save_data(Alpine, table, (start_time, end_time), file_path, verbose=True)\n",
    "        print(f\"Table {table} is saved.\")\n",
    "    except HttpResponseError as e:\n",
    "        print(f\"Table {table} is failed to save.\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.720703125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6882/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 4, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count: 24516 Size per entry: 558.68 Total size: 13.062094573974608 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, -1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segemented_query(Alpine, \"AADManagedIdentitySignInLogs\", (start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_size\n",
    "resutl = query_data(\"AADManagedIdentitySignInLogs | count\", (start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'executionTime': 0.0312273, 'resourceUsage': {'cache': {'shards': {'hot': {'hitbytes': 2142188, 'missbytes': 0, 'retrievebytes': 0}, 'cold': {'hitbytes': 0, 'missbytes': 0, 'retrievebytes': 0}, 'bypassbytes': 0}}, 'cpu': {'user': '00:00:00.0312500', 'kernel': '00:00:00.0156250', 'totalCpu': '00:00:00.0468750', 'breakdown': {'queryExecution': '00:00:00.0468750', 'queryPlanning': '00:00:00'}}, 'memory': {'peakPerNode': 65915136}, 'network': {'interClusterTotalBytes': 2437785, 'crossClusterTotalBytes': 0}}, 'inputDatasetStatistics': {'extents': {'total': 68, 'scanned': 40, 'scannedMinDatetime': '2024-06-18T00:00:00.0000000Z', 'scannedMaxDatetime': '2024-08-02T21:19:30.5753348Z'}, 'rows': {'total': 43242, 'scanned': 25069}, 'rowstores': {'scannedRows': 630, 'scannedValuesSize': 2124963}, 'shards': {'queriesGeneric': 33, 'queriesSpecialized': 0}}, 'datasetStatistics': [{'tableRowCount': 200, 'tableSize': 108997}], 'crossClusterResourceUsage': {}}}\n"
     ]
    }
   ],
   "source": [
    "duration = timedelta(hours=20)\n",
    "# end_time = start_time + duration\n",
    "\n",
    "resutl = query_data(\"AADManagedIdentitySignInLogs | limit 200\", (start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'executionTime': 0.0156376,\n",
       " 'resourceUsage': {'cache': {'shards': {'hot': {'hitbytes': 187666,\n",
       "     'missbytes': 0,\n",
       "     'retrievebytes': 0},\n",
       "    'cold': {'hitbytes': 0, 'missbytes': 0, 'retrievebytes': 0},\n",
       "    'bypassbytes': 0}},\n",
       "  'cpu': {'user': '00:00:00.0625000',\n",
       "   'kernel': '00:00:00.0468750',\n",
       "   'totalCpu': '00:00:00.1093750',\n",
       "   'breakdown': {'queryExecution': '00:00:00.1093750',\n",
       "    'queryPlanning': '00:00:00'}},\n",
       "  'memory': {'peakPerNode': 66525440},\n",
       "  'network': {'interClusterTotalBytes': 7858560, 'crossClusterTotalBytes': 0}},\n",
       " 'inputDatasetStatistics': {'extents': {'total': 68,\n",
       "   'scanned': 40,\n",
       "   'scannedMinDatetime': '2024-06-18T00:00:00.0000000Z',\n",
       "   'scannedMaxDatetime': '2024-08-02T21:19:30.5753348Z'},\n",
       "  'rows': {'total': 43242, 'scanned': 25069},\n",
       "  'rowstores': {'scannedRows': 627, 'scannedValuesSize': 2114383},\n",
       "  'shards': {'queriesGeneric': 4, 'queriesSpecialized': 0}},\n",
       " 'datasetStatistics': [{'tableRowCount': 1000, 'tableSize': 547144}],\n",
       " 'crossClusterResourceUsage': {}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl.statistics['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.36287339347594"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7858560 / 547144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'executionTime': 0.0468879,\n",
       " 'resourceUsage': {'cache': {'shards': {'hot': {'hitbytes': 1771040,\n",
       "     'missbytes': 0,\n",
       "     'retrievebytes': 0},\n",
       "    'cold': {'hitbytes': 0, 'missbytes': 0, 'retrievebytes': 0},\n",
       "    'bypassbytes': 0}},\n",
       "  'cpu': {'user': '00:00:00.0468750',\n",
       "   'kernel': '00:00:00.0312500',\n",
       "   'totalCpu': '00:00:00.0781250',\n",
       "   'breakdown': {'queryExecution': '00:00:00.0781250',\n",
       "    'queryPlanning': '00:00:00'}},\n",
       "  'memory': {'peakPerNode': 65546496},\n",
       "  'network': {'interClusterTotalBytes': 1267742, 'crossClusterTotalBytes': 0}},\n",
       " 'inputDatasetStatistics': {'extents': {'total': 68,\n",
       "   'scanned': 40,\n",
       "   'scannedMinDatetime': '2024-06-18T00:00:00.0000000Z',\n",
       "   'scannedMaxDatetime': '2024-08-02T21:19:30.5753348Z'},\n",
       "  'rows': {'total': 43242, 'scanned': 25069},\n",
       "  'rowstores': {'scannedRows': 626, 'scannedValuesSize': 2110866},\n",
       "  'shards': {'queriesGeneric': 31, 'queriesSpecialized': 0}},\n",
       " 'datasetStatistics': [{'tableRowCount': 100, 'tableSize': 54988}],\n",
       " 'crossClusterResourceUsage': {}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl.statistics['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9821961155161125"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "108997/54988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'executionTime': 0.0312273,\n",
       " 'resourceUsage': {'cache': {'shards': {'hot': {'hitbytes': 2142188,\n",
       "     'missbytes': 0,\n",
       "     'retrievebytes': 0},\n",
       "    'cold': {'hitbytes': 0, 'missbytes': 0, 'retrievebytes': 0},\n",
       "    'bypassbytes': 0}},\n",
       "  'cpu': {'user': '00:00:00.0312500',\n",
       "   'kernel': '00:00:00.0156250',\n",
       "   'totalCpu': '00:00:00.0468750',\n",
       "   'breakdown': {'queryExecution': '00:00:00.0468750',\n",
       "    'queryPlanning': '00:00:00'}},\n",
       "  'memory': {'peakPerNode': 65915136},\n",
       "  'network': {'interClusterTotalBytes': 2437785, 'crossClusterTotalBytes': 0}},\n",
       " 'inputDatasetStatistics': {'extents': {'total': 68,\n",
       "   'scanned': 40,\n",
       "   'scannedMinDatetime': '2024-06-18T00:00:00.0000000Z',\n",
       "   'scannedMaxDatetime': '2024-08-02T21:19:30.5753348Z'},\n",
       "  'rows': {'total': 43242, 'scanned': 25069},\n",
       "  'rowstores': {'scannedRows': 630, 'scannedValuesSize': 2124963},\n",
       "  'shards': {'queriesGeneric': 33, 'queriesSpecialized': 0}},\n",
       " 'datasetStatistics': [{'tableRowCount': 200, 'tableSize': 108997}],\n",
       " 'crossClusterResourceUsage': {}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl.statistics['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['resourceUsage']['network']['interClusterTotalBytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Count\n",
      "0  24516\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for k in resutl.tables:\n",
    "    m = pd.DataFrame(k.rows, columns=k.columns)\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12882"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutl.statistics['query']['resourceUsage']['network']['interClusterTotalBytes']\n",
    "# bytes to mib\n",
    "# resutl.statistics['query']['resourceUsage']['network']['interClusterTotalBytes'] / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'executionTime': 0.0156209, 'resourceUsage': {'cache': {'shards': {'hot': {'hitbytes': 35587, 'missbytes': 0, 'retrievebytes': 0}, 'cold': {'hitbytes': 0, 'missbytes': 0, 'retrievebytes': 0}, 'bypassbytes': 0}}, 'cpu': {'user': '00:00:00', 'kernel': '00:00:00', 'totalCpu': '00:00:00', 'breakdown': {'queryExecution': '00:00:00', 'queryPlanning': '00:00:00'}}, 'memory': {'peakPerNode': 65546752}, 'network': {'interClusterTotalBytes': 12882, 'crossClusterTotalBytes': 0}}, 'inputDatasetStatistics': {'extents': {'total': 68, 'scanned': 1, 'scannedMinDatetime': '2024-06-18T00:00:00.0000000Z', 'scannedMaxDatetime': '2024-06-18T00:00:00.0000000Z'}, 'rows': {'total': 43242, 'scanned': 215}, 'rowstores': {'scannedRows': 611, 'scannedValuesSize': 2061095}, 'shards': {'queriesGeneric': 1, 'queriesSpecialized': 0}}, 'datasetStatistics': [{'tableRowCount': 1, 'tableSize': 603}], 'crossClusterResourceUsage': {}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'network'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m duration \u001b[38;5;241m=\u001b[39m timedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# end_time = start_time + duration\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m resutl \u001b[38;5;241m=\u001b[39m \u001b[43mquery_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAADManagedIdentitySignInLogs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(resutl)\n",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mquery_data\u001b[1;34m(query, timpespan)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatistics)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# get total bytes processed\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatistics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnetwork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterClusterTotalBytes\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m LogsQueryStatus\u001b[38;5;241m.\u001b[39mSUCCESS:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtables\n",
      "\u001b[1;31mKeyError\u001b[0m: 'network'"
     ]
    }
   ],
   "source": [
    "\n",
    "ATEVET_17 = \"0fbd2874-9307-4572-b499-f8fa3cc75daf\"\n",
    "Alpine = \"e34d562e-ef12-4c4e-9bc0-7c6ae357c015\"\n",
    "def query_data(query, timpespan: Optional[Union[timedelta, Tuple[datetime, timedelta], Tuple[datetime, datetime]]]):\n",
    "    response = client.query_workspace(Alpine, query, timespan=timpespan, include_statistics=True)\n",
    "    print(response.statistics)\n",
    "    # get total bytes processed\n",
    "    print(response.statistics[\"network\"]['interClusterTotalBytes'])\n",
    "    if response.status == LogsQueryStatus.SUCCESS:\n",
    "        return response.tables\n",
    "    else:\n",
    "        return response.partial_data\n",
    "    \n",
    "    \n",
    "# 45 days\n",
    "start_time = datetime(2024, 6, 18, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "end_time = datetime(2024, 8, 2, 0, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "# for 3 hours\n",
    "duration = timedelta(hours=3)\n",
    "# end_time = start_time + duration\n",
    "\n",
    "resutl = query_data(\"AADManagedIdentitySignInLogs\", (start_time, duration))\n",
    "print(resutl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogsTable' object has no attribute 'to_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get stats\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mresutl\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogsTable' object has no attribute 'to_dict'"
     ]
    }
   ],
   "source": [
    "# get stats\n",
    "stats = resutl[0].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
