{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(data:dict):\n",
    "    \"\"\"Analyze the data and print out the results\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to be analyzed, load an \"agent log\" json file\n",
    "        \n",
    "    \"\"\"\n",
    "    total_len = len(data)\n",
    "    total_reward = 0\n",
    "    total_round = 0\n",
    "    non_zero_reward_count = 0\n",
    "    non_success_count = 0\n",
    "    \n",
    "\n",
    "    path_count = {}\n",
    "    reward_count = {}\n",
    "    round_count = {}\n",
    "    for k in data:\n",
    "        p = len(k['question_dict']['shortest_alert_path'])\n",
    "        if p not in path_count:\n",
    "            path_count[p] = 0\n",
    "            reward_count[p] = 0\n",
    "            round_count[p] = 0\n",
    "\n",
    "        if k['reward'] > 0 and k['reward'] < 1:\n",
    "            non_success_count += 1\n",
    "        if k['reward'] > 0:\n",
    "            non_zero_reward_count += 1\n",
    "        \n",
    "        # total\n",
    "        total_reward += k['reward']\n",
    "        total_round += (len(k[\"messages\"]) - 1) // 2\n",
    "\n",
    "        path_count[p] += 1\n",
    "        reward_count[p] += k['reward']\n",
    "        round_count[p] += (len(k[\"messages\"]) - 1) // 2\n",
    "\n",
    "    print(f\"Average reward: {total_reward}/{total_len} = {round(total_reward/total_len,6)}\")\n",
    "    print(f\"Average round: {total_round}/{total_len} = {round(total_round/total_len,6)}\")\n",
    "    print(f\"Non success / non-zero reward count: {non_success_count}/{non_zero_reward_count}\")\n",
    "\n",
    "    sorted_keys = sorted(path_count.keys())\n",
    "    for k in sorted_keys:\n",
    "        print(f\"Difficulty {k}: {round(reward_count[k], 2)}/{path_count[k]} = {round(reward_count[k]/path_count[k],6)} | Avg round: {round(round_count[k]/path_count[k], 2)}\")\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"total_len\": total_len,\n",
    "        \"total_reward\": total_reward,\n",
    "        \"total_round\": total_round,\n",
    "        \"non_zero_reward_count\": non_zero_reward_count,\n",
    "        \"non_success_count\": non_success_count,\n",
    "        \"path_count\": path_count,\n",
    "        \"reward_count\": reward_count,\n",
    "        \"round_count\": round_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Analysis for incident 55\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 5\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 34\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 38\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 134\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 166\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 39\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "********************\n",
      "Analysis for incident 322\n",
      "Average reward: 52.4/100 = 0.524\n",
      "Average round: 999/100 = 9.99\n",
      "Non success / non-zero reward count: 1/53\n",
      "Difficulty 1: 5/11 = 0.454545 | Avg round: 11.36\n",
      "Difficulty 3: 47.4/89 = 0.532584 | Avg round: 9.82\n",
      "********************\n",
      "****************************************\n",
      "****************************************\n",
      "Total analysis\n",
      "Total length: 800\n",
      "Total reward: 419.19999999999993\n",
      "Total round: 7992\n",
      "Difficulty 1: 40/88 = 0.454545\n",
      "Difficulty 3: 379.2/712 = 0.532584\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "log_path = \"C:/Users/amudgerikar/source/repos/SecRL/secgym/results/\"\n",
    "file_template = \"PromptSauceAgent_incident_166_agent_log_gpt-4o_111_alert.json\"\n",
    "\n",
    "incidents = [55, 5, 34, 38, 134, 166, 39, 322]\n",
    "#incidents = [5]\n",
    "\n",
    "total_len = 0\n",
    "total_reward = 0\n",
    "total_round = 0\n",
    "path_count = {}\n",
    "reward_count = {}\n",
    "\n",
    "\n",
    "for i in incidents:\n",
    "    print(\"*\"*20)\n",
    "    print(f\"Analysis for incident {i}\")\n",
    "\n",
    "    a = open(f\"{log_path}/{file_template.format(i)}\", \"r\")\n",
    "    b = json.load(a)\n",
    "    result_dict = analysis(b)\n",
    "\n",
    "    total_len += result_dict['total_len']\n",
    "    total_reward += result_dict['total_reward']\n",
    "    total_round += result_dict['total_round']\n",
    "    \n",
    "    for k in result_dict['path_count']:\n",
    "        if k not in path_count:\n",
    "            path_count[k] = 0\n",
    "            reward_count[k] = 0\n",
    "\n",
    "        path_count[k] += result_dict['path_count'][k]\n",
    "        reward_count[k] += result_dict['reward_count'][k]\n",
    "\n",
    "\n",
    "    print(\"*\"*20)\n",
    "    \n",
    "\n",
    "print(\"*\"*40)\n",
    "print(\"*\"*40)\n",
    "print(\"Total analysis\")\n",
    "print(f\"Total length: {total_len}\")\n",
    "print(f\"Total reward: {total_reward}\")\n",
    "print(f\"Total round: {total_round}\")\n",
    "\n",
    "sorted_keys = sorted(path_count.keys())\n",
    "for k in sorted_keys:\n",
    "    print(f\"Difficulty {k}: {round(reward_count[k], 2)}/{path_count[k]} = {round(reward_count[k]/path_count[k],6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
