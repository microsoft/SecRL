{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "def extract_from_one_file(data_folder, finetune_raw_folder):\n",
    "    \"\"\"\n",
    "    Save correct questions\n",
    "    \"\"\"\n",
    "    incidents = [5, 34, 38, 39, 55, 134, 166, 322]\n",
    "\n",
    "    data_key = data_folder.split(\"/\")[-1]\n",
    "    os.makedirs(finetune_raw_folder, exist_ok=True)\n",
    "    for iid in incidents:\n",
    "\n",
    "        # check if save path exists\n",
    "        save_path = f\"{finetune_raw_folder}/incident_{iid}.json\"\n",
    "        if os.path.exists(save_path):\n",
    "            # load\n",
    "            with open(save_path, \"r\") as f:\n",
    "                loaded_data = json.load(f)\n",
    "        else:\n",
    "            loaded_data = []\n",
    "\n",
    "        existed_data_keys = [f\"{data_folder}-{d['nodes']}\" for d in loaded_data]\n",
    "\n",
    "\n",
    "        file_name = f\"../secgym/final_results/{data_folder}/agent_incident_{iid}.json\"\n",
    "        with open(file_name, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        selected_data = []\n",
    "        for d in data:\n",
    "            if d['reward'] != 1:\n",
    "                continue\n",
    "            \n",
    "            if f\"{data_key}-{d['nodes']}\" in existed_data_keys:\n",
    "                continue\n",
    "\n",
    "            selected_data.append(\n",
    "                {\n",
    "                    \"messages\": d['messages'],\n",
    "                    \"question_dict\": d['question_dict'],\n",
    "                    \"nodes\": d['nodes'],\n",
    "                    \"data_folder\": data_folder,\n",
    "                }\n",
    "            )\n",
    "        loaded_data += selected_data\n",
    "        print(f\"incident {iid} has {len(loaded_data)} data\")\n",
    "        with open(save_path, \"w\") as f:\n",
    "            json.dump(loaded_data, f, indent=4)\n",
    "\n",
    "\n",
    "def prepare_finetune_data(\n",
    "    save_folder: str,\n",
    "    finetune_raw_folder: str,\n",
    "    train_incidents: list, # rest is test\n",
    "    pre_name: str = \"\"\n",
    "):\n",
    "    incidents = [5, 34, 38, 39, 55, 134, 166, 322]\n",
    "    train_data = []\n",
    "    test_incidents = [iid for iid in incidents if iid not in train_incidents]\n",
    "\n",
    "    for iid in incidents:\n",
    "        if iid in train_incidents:\n",
    "            with open(f\"{finetune_raw_folder}/incident_{iid}.json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            # only get the messages\n",
    "            data = [{\"messages\": d[\"messages\"]} for d in data]\n",
    "            train_data += data\n",
    "    \n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    with open(f\"{save_folder}/{pre_name}_train.jsonl\", \"w\") as f:\n",
    "        for d in train_data:\n",
    "            f.write(json.dumps(d) + \"\\n\")\n",
    "        \n",
    "    print(f\"train data has {len(train_data)} data\")\n",
    "    with open(f\"{save_folder}/test_incident_ids.json\", \"w\") as f:\n",
    "        json.dump(test_incidents, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting BaselineAgent_gpt-4o_c70_alert_level_t0_s25_trial1\n",
      "incident 5 has 52 data\n",
      "incident 34 has 44 data\n",
      "incident 38 has 5 data\n",
      "incident 39 has 44 data\n",
      "incident 55 has 48 data\n",
      "incident 134 has 39 data\n",
      "incident 166 has 32 data\n",
      "incident 322 has 38 data\n",
      "Extracting BaselineAgent_4o-mini_c71_alert_level_t0_s25_trial1\n",
      "incident 5 has 52 data\n",
      "incident 34 has 44 data\n",
      "incident 38 has 5 data\n",
      "incident 39 has 44 data\n",
      "incident 55 has 48 data\n",
      "incident 134 has 39 data\n",
      "incident 166 has 32 data\n",
      "incident 322 has 38 data\n",
      "Extracting BaselineAgent_o1-mini_c92_alert_level_t0_s25_trial1\n",
      "incident 5 has 52 data\n",
      "incident 34 has 44 data\n",
      "incident 38 has 5 data\n",
      "incident 39 has 44 data\n",
      "incident 55 has 48 data\n",
      "incident 134 has 39 data\n",
      "incident 166 has 32 data\n",
      "incident 322 has 38 data\n",
      "Extracting BaselineAgent_o3-mini_c99_alert_level_t0_s25_trial1\n",
      "incident 5 has 52 data\n",
      "incident 34 has 44 data\n",
      "incident 38 has 5 data\n",
      "incident 39 has 44 data\n",
      "incident 55 has 48 data\n",
      "incident 134 has 39 data\n",
      "incident 166 has 32 data\n",
      "incident 322 has 38 data\n"
     ]
    }
   ],
   "source": [
    "baselines = [\n",
    "    \"BaselineAgent_gpt-4o_c70_alert_level_t0_s25_trial1\",\n",
    "    \"BaselineAgent_4o-mini_c71_alert_level_t0_s25_trial1\",\n",
    "    \"BaselineAgent_o1-mini_c92_alert_level_t0_s25_trial1\",\n",
    "    \"BaselineAgent_o3-mini_c99_alert_level_t0_s25_trial1\"\n",
    "]\n",
    "\n",
    "for b in baselines:\n",
    "    print(f\"Extracting {b}\")\n",
    "    extract_from_one_file(b, \"finetune_raw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data has 253 data\n",
      "train data has 253 data\n",
      "train data has 250 data\n",
      "train data has 258 data\n",
      "train data has 225 data\n",
      "train data has 270 data\n",
      "train data has 254 data\n"
     ]
    }
   ],
   "source": [
    "prepare_finetune_data(\"finetune_data\", \"finetune_raw\", [5, 39, 55, 134, 166, 322], \"no34_38\")\n",
    "\n",
    "cv_sets = [\n",
    "    [5, 39, 55, 134, 166, 322], # remove 34, 38\n",
    "    [34, 38, 39, 55, 134, 166, 322], # remove 5\n",
    "    [5, 34, 38, 55, 134, 166, 322], # remove 39\n",
    "    [5, 34, 38, 39, 55, 166], # remove 134, 322\n",
    "    [5, 34, 38, 39, 55, 134, 322], # remove 166\n",
    "    [5, 34, 38, 39, 134, 166, 322], # remove 55\n",
    "]\n",
    "\n",
    "for i, cv in enumerate(cv_sets):\n",
    "    prepare_finetune_data(\"finetune_data\", \"finetune_raw\", cv, f\"cv{i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_38_qa_incident_o1-ga_c42.json 11\n",
      "incident_34_qa_incident_o1-ga_c42.json 82\n",
      "incident_5_qa_incident_o1-ga_c42.json 98\n",
      "incident_39_qa_incident_o1-ga_c42.json 98\n",
      "incident_134_qa_incident_o1-ga_c42.json 57\n",
      "incident_322_qa_incident_o1-ga_c42.json 56\n",
      "incident_166_qa_incident_o1-ga_c42.json 87\n",
      "incident_55_qa_incident_o1-ga_c42.json 100\n"
     ]
    }
   ],
   "source": [
    "qpath = \"/Users/kevin/Downloads/SecRL/secgym/env/questions/min_overlap/test\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "for file in os.listdir(qpath):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(f\"{qpath}/{file}\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            print(file, len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
