{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_overlap_score(path1, path2, beta=0.01, delta=0):\n",
    "#     \"\"\"\n",
    "#     Calculate an overlap score between two paths, inspired by the Jaccard Index,\n",
    "#     with a small penalty for unshared edges.\n",
    "\n",
    "#     Parameters:\n",
    "#         path1 (list): The first path as a sequence of nodes.\n",
    "#         path2 (list): The second path as a sequence of nodes.\n",
    "#         beta (float): Weight for penalizing unshared edges.\n",
    "#         delta (float): Baseline adjustment to ensure non-negativity (optional).\n",
    "\n",
    "#     Returns:\n",
    "#         float: Overlap score.\n",
    "#     \"\"\"\n",
    "#     # Get edges for both paths\n",
    "#     edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "#     edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "#     # Calculate shared and unshared edges\n",
    "#     shared_edges = edges1 & edges2\n",
    "#     unshared_edges = edges1 ^ edges2  # Symmetric difference\n",
    "#     total_edges = edges1 | edges2    # Union of all edges\n",
    "\n",
    "#     # Compute Jaccard Index-inspired score with penalty for unshared edges\n",
    "#     jaccard_score = len(shared_edges) / len(total_edges) if total_edges else 0\n",
    "#     penalty = beta * len(unshared_edges) / len(total_edges) if total_edges else 0\n",
    "#     score = jaccard_score - penalty\n",
    "\n",
    "#     # Add baseline adjustment to ensure non-negativity\n",
    "#     # score = max(0, score + delta)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "zero_count = 0\n",
    "noshare_count = 0\n",
    "\n",
    "def compute_overlap_score(path1, path2, alpha=3, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate the overlap score between two paths based on shared and unshared edges.\n",
    "\n",
    "    Parameters:\n",
    "        path (list): The first path as a sequence of nodes.\n",
    "        other_path (list): The second path as a sequence of nodes.\n",
    "        alpha (float): Weight for shared edges (positive contribution).\n",
    "        beta (float): Weight for unshared edges (negative contribution).\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap score.\n",
    "    \"\"\"\n",
    "    if len(path1) <= 1 or len(path2) <= 1:\n",
    "        return 0\n",
    "    # Get edges for both paths\n",
    "    edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "    edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "    # Shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    if len(shared_edges) == 0:\n",
    "        return 0\n",
    "    unshared_edges = edges1 ^ edges2 \n",
    "\n",
    "    # Compute score\n",
    "    score = alpha * len(shared_edges) - beta * len(unshared_edges) / (len(edges1) + len(edges2))\n",
    "    # bound: [-beta, alpha]\n",
    "    # resacle to [0, 1]\n",
    "    # score = (score + beta) / (alpha + beta)\n",
    " \n",
    "    return score\n",
    "\n",
    "def split_train_test(all_paths:dict, train_ratio:float = 0.9):\n",
    "    \"\"\"\n",
    "    all_path = [{'start_alert': int, 'end_alert': int}, ...]\n",
    "\n",
    "    {\n",
    "        'start_alert': 24,\n",
    "        'end_alert': 11,\n",
    "        'start_entities': [12],\n",
    "        'end_entities': [9],\n",
    "        'shortest_alert_path': [24, 9, 11]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # construct a dictionary to map the path to the original dictionary\n",
    "    random.shuffle(all_paths)\n",
    "    path_to_dict = {}\n",
    "    for path in all_paths:\n",
    "        # extract the 0, 2, 4, 6, ... index of the path\n",
    "        extracted = path['shortest_alert_path'][::2]\n",
    "        path_to_dict[tuple(extracted)] = path\n",
    "    \n",
    "    # prepare the alert paths\n",
    "    alert_paths = list(path_to_dict.keys())\n",
    "    max_length = max(len(p) for p in alert_paths)\n",
    "    total = len(alert_paths)\n",
    "    train_len = int(total * train_ratio)\n",
    "    test_len = total - train_len\n",
    "\n",
    "\n",
    "    # fill the score matrix\n",
    "    score_matrix = [[-1] * len(alert_paths)  for _ in range(len(alert_paths))]\n",
    "    theta = 0.1 # default train length score\n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i == j:\n",
    "                score_matrix[i][j] = 0\n",
    "                continue\n",
    "            if score_matrix[j][i] != -1:\n",
    "                score_matrix[i][j] = score_matrix[j][i]\n",
    "            score_matrix[i][j] = compute_overlap_score(alert_paths[i], alert_paths[j])\n",
    "        \n",
    "    # split the train and test set\n",
    "    zero_ratio_count = 0\n",
    "    large_ratio_count = 0\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    for i in range(total):\n",
    "        p = alert_paths[i]\n",
    "        if train_keys == [] or test_keys == []:\n",
    "            ratio = 0.5\n",
    "        elif len(train_keys) >= train_len:\n",
    "            test_keys += alert_paths[i:]\n",
    "            break\n",
    "        elif len(test_keys) >= test_len:\n",
    "            train_keys += alert_paths[i:]\n",
    "            break\n",
    "        else:\n",
    "            \n",
    "            train_score = sum(score_matrix[i][alert_paths.index(k)] for k in train_keys) / len(train_keys)\n",
    "            test_score = sum(score_matrix[i][alert_paths.index(k)] for k in test_keys) / len(test_keys)\n",
    "            # if train_score is higher, the point should be more likely to be in test set\n",
    "            try: \n",
    "                # use softmax\n",
    "                exp_train = np.exp(train_score)\n",
    "                exp_test = np.exp(test_score)\n",
    "                ratio = exp_train / (exp_train + exp_test)\n",
    "\n",
    "            \n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                zero_ratio_count += 1\n",
    "                ratio = 0.5\n",
    "\n",
    "            # print(\"len train:\", len(train_keys), \"len test:\", len(test_keys))\n",
    "            # print(\"Train score:\", train_score, \"Test score:\", test_score, \"Ratio:\", ratio)\n",
    "\n",
    "            # add length influence\n",
    "            # ratio = ratio * (theta / ( theta + len(p) / max_length))\n",
    "\n",
    "        # weighted random selection\n",
    "        if random.random() < ratio:\n",
    "            train_keys.append(p)\n",
    "        else:\n",
    "            test_keys.append(p)\n",
    "\n",
    "    # ----------------- compare with random selection -----------------\n",
    "    total_score = 0\n",
    "    for k in train_keys:\n",
    "        for j in test_keys:\n",
    "            total_score += score_matrix[alert_paths.index(k)][alert_paths.index(j)]\n",
    "    \n",
    "    # take first k as train set\n",
    "    compare_train_set = []\n",
    "    compare_test_set = []\n",
    "    for i in range(train_len):\n",
    "        if len(compare_train_set) >= train_len:\n",
    "            compare_test_set += alert_paths[i:]\n",
    "            break\n",
    "        elif len(compare_test_set) >= test_len:\n",
    "            compare_train_set += alert_paths[i:]\n",
    "            break\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            compare_train_set.append(alert_paths[i])\n",
    "        else:\n",
    "            compare_test_set.append(alert_paths[i])\n",
    "\n",
    "    compare_score = 0\n",
    "    for k in compare_train_set:\n",
    "        for j in compare_test_set:\n",
    "            compare_score += score_matrix[alert_paths.index(k)][alert_paths.index(j)]\n",
    "\n",
    "    print(\"Total score:\", total_score, \"Comparison score:\", compare_score)\n",
    "    # -----------------------------------------------------------------\n",
    "    return total_score, compare_score\n",
    "\n",
    "    # map back to original paths\n",
    "    final_train_set = [path_to_dict[p1] for p1 in train_keys]\n",
    "    final_test_set = [path_to_dict[p2] for p2 in test_keys]\n",
    "    return final_train_set, final_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = {\"a\": 1, \"b\": 2}\n",
    "b = {\"a\": 2, \"b\": None}\n",
    "c = {**a, **b}\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alert paths: 728. Expected: alert_num ^ 2 = 729, Selected: 728\n",
      "0.8626373626373627\n",
      "Total score: 1996.978571428579 Comparison score: 1735.361904761909\n",
      "Average total score: 199.6978571428579\n",
      "Average compare score: 173.5361904761909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compare_score = 0\n",
    "total_score = 0\n",
    "for i in range(10):\n",
    "    graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files/incident_55.graphml\"\n",
    "\n",
    "    # load the graph\n",
    "    alert_graph = AlertGraph()\n",
    "    alert_graph.load_graph_from_graphml(graphfile)\n",
    "\n",
    "    all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "    if len(all_paths) < 150:\n",
    "        train_ratio = 0.285\n",
    "    else:\n",
    "        train_ratio = 1 - 100 / len(all_paths)\n",
    "        print(train_ratio)\n",
    "\n",
    "    tscore, cscore = split_train_test(all_paths)\n",
    "    total_score += tscore\n",
    "    compare_score += cscore\n",
    "    break\n",
    "\n",
    "# avg\n",
    "print(\"Average total score:\", total_score / 10)\n",
    "print(\"Average compare score:\", compare_score / 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_overlap_score(path1, path2, beta=0.01, delta=0):\n",
    "#     \"\"\"\n",
    "#     Calculate an overlap score between two paths, inspired by the Jaccard Index,\n",
    "#     with a small penalty for unshared edges.\n",
    "\n",
    "#     Parameters:\n",
    "#         path1 (list): The first path as a sequence of nodes.\n",
    "#         path2 (list): The second path as a sequence of nodes.\n",
    "#         beta (float): Weight for penalizing unshared edges.\n",
    "#         delta (float): Baseline adjustment to ensure non-negativity (optional).\n",
    "\n",
    "#     Returns:\n",
    "#         float: Overlap score.\n",
    "#     \"\"\"\n",
    "#     # Get edges for both paths\n",
    "#     edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "#     edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "#     # Calculate shared and unshared edges\n",
    "#     shared_edges = edges1 & edges2\n",
    "#     unshared_edges = edges1 ^ edges2  # Symmetric difference\n",
    "#     total_edges = edges1 | edges2    # Union of all edges\n",
    "\n",
    "#     # Compute Jaccard Index-inspired score with penalty for unshared edges\n",
    "#     jaccard_score = len(shared_edges) / len(total_edges) if total_edges else 0\n",
    "#     penalty = beta * len(unshared_edges) / len(total_edges) if total_edges else 0\n",
    "#     score = jaccard_score - penalty\n",
    "\n",
    "#     # Add baseline adjustment to ensure non-negativity\n",
    "#     # score = max(0, score + delta)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "zero_count = 0\n",
    "noshare_count = 0\n",
    "\n",
    "def compute_overlap_score(path1, path2, alpha=3, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate the overlap score between two paths based on shared and unshared edges.\n",
    "\n",
    "    Parameters:\n",
    "        path (list): The first path as a sequence of nodes.\n",
    "        other_path (list): The second path as a sequence of nodes.\n",
    "        alpha (float): Weight for shared edges (positive contribution).\n",
    "        beta (float): Weight for unshared edges (negative contribution).\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap score.\n",
    "    \"\"\"\n",
    "    if len(path1) <= 1 or len(path2) <= 1:\n",
    "        return 0\n",
    "    # Get edges for both paths\n",
    "    edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "    edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "    # Shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    if len(shared_edges) == 0:\n",
    "        return 0\n",
    "    unshared_edges = edges1 ^ edges2 \n",
    "\n",
    "    # Compute score\n",
    "    score = alpha * len(shared_edges) - beta * len(unshared_edges) / (len(edges1) + len(edges2))\n",
    "    # bound: [-beta, alpha]\n",
    "    # resacle to [0, 1]\n",
    "    # score = (score + beta) / (alpha + beta)\n",
    " \n",
    "    return score\n",
    "\n",
    "def split_train_test(all_paths:dict, train_ratio:float = 0.9):\n",
    "    \"\"\"\n",
    "    all_path = [{'start_alert': int, 'end_alert': int}, ...]\n",
    "\n",
    "    {\n",
    "        'start_alert': 24,\n",
    "        'end_alert': 11,\n",
    "        'start_entities': [12],\n",
    "        'end_entities': [9],\n",
    "        'shortest_alert_path': [24, 9, 11]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # construct a dictionary to map the path to the original dictionary\n",
    "    random.shuffle(all_paths)\n",
    "    path_to_dict = {}\n",
    "    for path in all_paths:\n",
    "        # extract the 0, 2, 4, 6, ... index of the path\n",
    "        extracted = path['shortest_alert_path'][::2]\n",
    "        path_to_dict[tuple(extracted)] = path\n",
    "    \n",
    "    # prepare the alert paths\n",
    "    alert_paths = list(path_to_dict.keys())\n",
    "    max_length = max(len(p) for p in alert_paths)\n",
    "    total = len(alert_paths)\n",
    "    train_len = int(total * train_ratio)\n",
    "    test_len = total - train_len\n",
    "\n",
    "    # length weight\n",
    "    lweights = []\n",
    "    for p in alert_paths:\n",
    "        lweights.append(len(p) / max_length)\n",
    "    \n",
    "    # normalize the length weight\n",
    "    lweights = np.array(lweights)\n",
    "    lweights = lweights / lweights.sum()\n",
    "    avg = lweights.mean()\n",
    "\n",
    "    score_matrix = [[-1000] * len(alert_paths)  for _ in range(len(alert_paths))]\n",
    "    def get_score(i, j):\n",
    "        if score_matrix[i][j] != -1000:\n",
    "            return score_matrix[i][j]\n",
    "        if i==j:\n",
    "            score_matrix[i][j] = 0\n",
    "            return 0\n",
    "        elif score_matrix[j][i] != -1000:\n",
    "            score_matrix[i][j] = score_matrix[j][i]\n",
    "            return score_matrix[i][j]\n",
    "        score_matrix[i][j] = compute_overlap_score(alert_paths[i], alert_paths[j])\n",
    "        return score_matrix[i][j]\n",
    "\n",
    "    # split the train and test set\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    for i in range(total):\n",
    "        p = alert_paths[i]\n",
    "        if train_keys == [] or test_keys == []:\n",
    "            ratio = lweights[i] / (lweights[i] + avg)\n",
    "            print(\"LengthRatio:\", ratio)\n",
    "        elif len(train_keys) >= train_len:\n",
    "            test_keys += alert_paths[i:]\n",
    "            break\n",
    "        elif len(test_keys) >= test_len:\n",
    "            train_keys += alert_paths[i:]\n",
    "            break\n",
    "        else:\n",
    "            train_score = sum(get_score(i, alert_paths.index(k)) for k in train_keys) / len(train_keys)\n",
    "            test_score = sum(get_score(i, alert_paths.index(k)) for k in test_keys) / len(test_keys)\n",
    "            # if train_score is higher, the point should be more likely to be in test set\n",
    "\n",
    "            try: \n",
    "                # use softmax\n",
    "                exp_train = np.exp(train_score)\n",
    "                exp_test = np.exp(test_score)\n",
    "                ratio = exp_train / (exp_train + exp_test)\n",
    "            except ZeroDivisionError:\n",
    "                ratio = 0.5\n",
    "\n",
    "            # print(\"len train:\", len(train_keys), \"len test:\", len(test_keys))\n",
    "            # print(\"Train score:\", train_score, \"Test score:\", test_score, \"Ratio:\", ratio)\n",
    "\n",
    "            # add length influence\n",
    "            # ratio = ratio * (theta / ( theta + len(p) / max_length))\n",
    "\n",
    "        # weighted random selection\n",
    "        if random.random() < ratio:\n",
    "            train_keys.append(p)\n",
    "        else:\n",
    "            test_keys.append(p)\n",
    "\n",
    "    # ----------------- compare with random selection -----------------\n",
    "    total_score = 0\n",
    "    for k in train_keys:\n",
    "        for j in test_keys:\n",
    "            total_score += get_score(alert_paths.index(k), alert_paths.index(j))\n",
    "    \n",
    "    # take first k as train set\n",
    "    compare_train_set = []\n",
    "    compare_test_set = []\n",
    "    for i in range(train_len):\n",
    "        if len(compare_train_set) >= train_len:\n",
    "            compare_test_set += alert_paths[i:]\n",
    "            break\n",
    "        elif len(compare_test_set) >= test_len:\n",
    "            compare_train_set += alert_paths[i:]\n",
    "            break\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            compare_train_set.append(alert_paths[i])\n",
    "        else:\n",
    "            compare_test_set.append(alert_paths[i])\n",
    "\n",
    "    compare_score = 0\n",
    "    for k in compare_train_set:\n",
    "        for j in compare_test_set:\n",
    "            compare_score += get_score(alert_paths.index(k), alert_paths.index(j))\n",
    "\n",
    "    print(\"Total score:\", total_score, \"Comparison score:\", compare_score)\n",
    "    # -----------------------------------------------------------------\n",
    "    return total_score, compare_score\n",
    "\n",
    "    # map back to original paths\n",
    "    final_train_set = [path_to_dict[p1] for p1 in train_keys]\n",
    "    final_test_set = [path_to_dict[p2] for p2 in test_keys]\n",
    "    return final_train_set, final_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alert paths: 728. Expected: alert_num ^ 2 = 729, Selected: 728\n",
      "0.8626373626373627\n",
      "LengthRatio: 0.6451612903225806\n",
      "LengthRatio: 0.5217391304347826\n",
      "LengthRatio: 0.5925925925925926\n",
      "LengthRatio: 0.5217391304347826\n",
      "LengthRatio: 0.4210526315789473\n",
      "LengthRatio: 0.5925925925925926\n",
      "LengthRatio: 0.6451612903225806\n",
      "LengthRatio: 0.4210526315789473\n",
      "LengthRatio: 0.5217391304347826\n",
      "LengthRatio: 0.5217391304347826\n",
      "Total score: 2115.2976190476247 Comparison score: 2147.304761904765\n",
      "Average total score: 211.52976190476247\n",
      "Average compare score: 214.7304761904765\n"
     ]
    }
   ],
   "source": [
    "from secgym.qagen.alert_graph import AlertGraph\n",
    "\n",
    "compare_score = 0\n",
    "total_score = 0\n",
    "for i in range(10):\n",
    "    graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files/incident_55.graphml\"\n",
    "\n",
    "    # load the graph\n",
    "    alert_graph = AlertGraph()\n",
    "    alert_graph.load_graph_from_graphml(graph_path)\n",
    "\n",
    "    all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "    if len(all_paths) < 150:\n",
    "        train_ratio = 0.285\n",
    "    else:\n",
    "        train_ratio = 1 - 100 / len(all_paths)\n",
    "        print(train_ratio)\n",
    "\n",
    "    tscore, cscore = split_train_test(all_paths)\n",
    "    total_score += tscore\n",
    "    compare_score += cscore\n",
    "    break\n",
    "\n",
    "# avg\n",
    "print(\"Average total score:\", total_score / 10)\n",
    "print(\"Average compare score:\", compare_score / 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{23.34: 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alert paths: 728. Expected: alert_num ^ 2 = 729, Selected: 728\n",
      "0.8626373626373627\n",
      "0.382,0.392,0.299,0.3,0.303,0.379,0.393,0.276,0.316,0.343,0.187,0.279,0.214,0.317,0.33,0.34,0.2,0.29,0.304,0.342,0.38,0.29,0.312,0.278,0.351,0.343,0.283,0.285,0.267,0.276,0.246,0.376,0.234,0.418,0.286,0.326,0.404,0.316,0.292,0.315,0.348,0.242,0.325,0.365,0.249,0.275,0.322,0.336,0.243,0.264,0.328,0.291,0.325,0.242,0.285,0.303,0.282,0.361,0.279,0.341,0.3,0.27,0.299,0.231,0.419,0.252,0.499,0.253,0.334,0.232,0.369,0.436,0.212,0.231,0.265,0.366,0.348,0.386,0.35,0.275,0.391,0.32,0.288,0.323,0.331,0.372,0.307,0.345,0.402,0.283,0.48,0.288,0.398,0.22,0.218,0.264,0.238,0.342,0.291,0.387,\n",
      "Best score: 2603.645238095249\n",
      "[1950.8428571428622, 2401.3500000000095, 1830.3928571428596, 1679.823809523813, 1931.0285714285783, 1955.1880952380986, 2155.6452380952483, 1538.0071428571453, 2019.2904761904824, 2117.9142857142906, 1350.8738095238086, 1708.7857142857156, 1113.9833333333336, 1728.2309523809563, 1970.5571428571495, 2057.554761904766, 1219.238095238096, 1904.9238095238131, 1637.3714285714318, 1861.3809523809566, 2284.6547619047747, 1639.6071428571445, 1798.685714285719, 2035.1500000000071, 2049.7380952381013, 1967.573809523815, 1768.9642857142892, 1798.9666666666726, 1705.8238095238123, 1198.4476190476182, 1386.223809523812, 2048.1785714285775, 1450.5833333333337, 2330.535714285723, 1743.8428571428624, 1799.1904761904814, 2268.1357142857255, 1539.2380952380963, 1606.7952380952397, 1858.9690476190515, 2196.3809523809605, 1195.357142857142, 1770.5404761904806, 2283.833333333343, 1420.250000000003, 1679.3976190476208, 2138.6571428571515, 2070.8666666666722, 1138.0761904761903, 1768.150000000003, 1941.1476190476233, 1716.5785714285742, 2026.4761904761967, 1386.5190476190498, 1665.673809523814, 1521.0785714285737, 1690.178571428575, 2045.083333333343, 1514.195238095238, 1861.8857142857196, 1925.3928571428637, 1706.49047619048, 1453.9976190476202, 1446.4619047619087, 2037.1714285714363, 1375.6809523809545, 2462.7238095238217, 1674.7952380952413, 2143.4523809523907, 1401.0761904761926, 2123.2285714285786, 2330.933333333339, 1302.7095238095242, 1249.7809523809515, 1588.566666666668, 2132.9119047619133, 2267.0476190476274, 2176.6214285714354, 2095.642857142863, 1509.8190476190518, 2200.5238095238137, 1805.3976190476267, 1515.228571428573, 1615.6214285714302, 1966.1404761904846, 2256.6238095238173, 1856.91190476191, 2018.3380952381, 2237.259523809532, 1595.4357142857157, 2603.645238095249, 1671.914285714289, 2071.464285714289, 1117.133333333333, 1393.414285714286, 1730.3452380952447, 1567.8500000000008, 2069.900000000005, 1699.5142857142885, 2180.6523809523896]\n"
     ]
    }
   ],
   "source": [
    "from secgym.qagen.alert_graph import AlertGraph\n",
    "\n",
    "compare_score = 0\n",
    "total_score = 0\n",
    "for i in range(10):\n",
    "    graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files/incident_55.graphml\"\n",
    "\n",
    "    # load the graph\n",
    "    alert_graph = AlertGraph()\n",
    "    alert_graph.load_graph_from_graphml(graph_path)\n",
    "\n",
    "    all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "    if len(all_paths) < 150:\n",
    "        train_ratio = 0.285\n",
    "    else:\n",
    "        train_ratio = 1 - 100 / len(all_paths)\n",
    "        print(train_ratio)\n",
    "\n",
    "    split_train_test(all_paths)\n",
    "    # total_score += tscore\n",
    "    # compare_score += cscore\n",
    "    break\n",
    "\n",
    "# avg\n",
    "# print(\"Average total score:\", total_score / 10)\n",
    "# print(\"Average compare score:\", compare_score / 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alert paths: 728. Expected: alert_num ^ 2 = 729, Selected: 728\n",
      "0.8626373626373627\n",
      "0.356,0.454,0.304,0.366,0.332,0.245,0.424,0.426,0.324,0.297,0.283,0.291,0.237,0.368,0.265,0.299,0.283,0.315,0.499,0.419,0.319,0.341,0.345,0.442,0.234,0.329,0.314,0.289,0.264,0.276,0.313,0.303,0.353,0.381,0.313,0.361,0.333,0.257,0.332,0.266,0.263,0.428,0.241,0.288,0.253,0.368,0.378,0.226,0.4,0.28,0.265,0.304,0.262,0.291,0.336,0.3,0.243,0.289,0.303,0.361,0.282,0.434,0.324,0.381,0.359,0.281,0.352,0.411,0.312,0.321,0.39,0.335,0.382,0.303,0.338,0.263,0.279,0.429,0.254,0.234,0.246,0.276,0.354,0.391,0.341,0.247,0.339,0.373,0.352,0.356,0.297,0.388,0.244,0.306,0.367,0.337,0.332,0.285,0.236,0.376,\n",
      "Best score: 2994.3166666666757\n",
      "[2465.9976190476254, 2839.8238095238207, 2296.580952380953, 2340.7095238095267, 2323.9071428571497, 1931.3142857142902, 2953.145238095249, 2900.235714285721, 2454.0023809523814, 2030.3500000000004, 2042.2619047619064, 2377.5619047619125, 1693.788095238095, 2389.992857142865, 1811.4785714285736, 2311.0880952381, 2367.1428571428614, 2371.033333333335, 2994.3166666666757, 2912.926190476202, 2454.8261904761916, 2540.7238095238117, 2657.302380952385, 2765.659523809535, 1816.3952380952355, 2336.266666666671, 1814.3190476190503, 1982.0595238095264, 1842.6166666666688, 2107.961904761902, 2200.469047619046, 2340.2190476190503, 2566.8238095238157, 2748.000000000007, 2316.650000000003, 2655.7095238095294, 2398.0142857142896, 1754.883333333333, 2467.326190476194, 2249.604761904764, 2048.297619047619, 2710.0738095238157, 1784.052380952382, 2107.833333333332, 1766.6166666666684, 2648.1238095238205, 2790.959523809536, 1499.5333333333303, 2835.707142857153, 2185.0357142857156, 2122.0404761904765, 2327.328571428571, 1877.9880952380945, 2117.083333333334, 2486.4071428571447, 2267.3952380952337, 1865.2095238095217, 1945.95476190476, 2065.469047619043, 2326.9976190476186, 2272.259523809528, 2818.1690476190615, 2327.6047619047654, 2577.6238095238164, 2490.480952380956, 1856.7047619047628, 2530.4500000000053, 2603.7619047619123, 2176.9166666666674, 2199.202380952383, 2662.8476190476263, 2405.516666666673, 2363.4904761904786, 2051.4690476190476, 2257.1261904761923, 1985.5619047619048, 1918.5833333333321, 2637.9000000000115, 2019.1666666666667, 1805.2976190476168, 1834.1309523809537, 1744.742857142857, 2312.2357142857186, 2622.269047619057, 2387.4428571428584, 2049.580952380951, 2193.9238095238134, 2618.1500000000083, 2433.6809523809566, 2632.5261904761996, 2320.378571428576, 2940.2428571428677, 1807.2999999999984, 2229.14047619048, 2640.9523809523866, 2485.750000000001, 2356.5833333333358, 2323.7952380952383, 1806.569047619045, 2674.3738095238177]\n"
     ]
    }
   ],
   "source": [
    "from secgym.qagen.alert_graph import AlertGraph\n",
    "\n",
    "compare_score = 0\n",
    "total_score = 0\n",
    "for i in range(10):\n",
    "    graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files/incident_55.graphml\"\n",
    "\n",
    "    # load the graph\n",
    "    alert_graph = AlertGraph()\n",
    "    alert_graph.load_graph_from_graphml(graph_path)\n",
    "\n",
    "    all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "    if len(all_paths) < 150:\n",
    "        train_ratio = 0.285\n",
    "    else:\n",
    "        train_ratio = 1 - 100 / len(all_paths)\n",
    "        print(train_ratio)\n",
    "\n",
    "    split_train_test(all_paths)\n",
    "    # total_score += tscore\n",
    "    # compare_score += cscore\n",
    "    break\n",
    "\n",
    "# avg\n",
    "# print(\"Average total score:\", total_score / 10)\n",
    "# print(\"Average compare score:\", compare_score / 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used: 2299.7549761904797\n",
      "Not Used: 1810.198333333338\n"
     ]
    }
   ],
   "source": [
    "used = [2465.9976190476254, 2839.8238095238207, 2296.580952380953, 2340.7095238095267, 2323.9071428571497, 1931.3142857142902, 2953.145238095249, 2900.235714285721, 2454.0023809523814, 2030.3500000000004, 2042.2619047619064, 2377.5619047619125, 1693.788095238095, 2389.992857142865, 1811.4785714285736, 2311.0880952381, 2367.1428571428614, 2371.033333333335, 2994.3166666666757, 2912.926190476202, 2454.8261904761916, 2540.7238095238117, 2657.302380952385, 2765.659523809535, 1816.3952380952355, 2336.266666666671, 1814.3190476190503, 1982.0595238095264, 1842.6166666666688, 2107.961904761902, 2200.469047619046, 2340.2190476190503, 2566.8238095238157, 2748.000000000007, 2316.650000000003, 2655.7095238095294, 2398.0142857142896, 1754.883333333333, 2467.326190476194, 2249.604761904764, 2048.297619047619, 2710.0738095238157, 1784.052380952382, 2107.833333333332, 1766.6166666666684, 2648.1238095238205, 2790.959523809536, 1499.5333333333303, 2835.707142857153, 2185.0357142857156, 2122.0404761904765, 2327.328571428571, 1877.9880952380945, 2117.083333333334, 2486.4071428571447, 2267.3952380952337, 1865.2095238095217, 1945.95476190476, 2065.469047619043, 2326.9976190476186, 2272.259523809528, 2818.1690476190615, 2327.6047619047654, 2577.6238095238164, 2490.480952380956, 1856.7047619047628, 2530.4500000000053, 2603.7619047619123, 2176.9166666666674, 2199.202380952383, 2662.8476190476263, 2405.516666666673, 2363.4904761904786, 2051.4690476190476, 2257.1261904761923, 1985.5619047619048, 1918.5833333333321, 2637.9000000000115, 2019.1666666666667, 1805.2976190476168, 1834.1309523809537, 1744.742857142857, 2312.2357142857186, 2622.269047619057, 2387.4428571428584, 2049.580952380951, 2193.9238095238134, 2618.1500000000083, 2433.6809523809566, 2632.5261904761996, 2320.378571428576, 2940.2428571428677, 1807.2999999999984, 2229.14047619048, 2640.9523809523866, 2485.750000000001, 2356.5833333333358, 2323.7952380952383, 1806.569047619045, 2674.3738095238177]\n",
    "not_used = [1950.8428571428622, 2401.3500000000095, 1830.3928571428596, 1679.823809523813, 1931.0285714285783, 1955.1880952380986, 2155.6452380952483, 1538.0071428571453, 2019.2904761904824, 2117.9142857142906, 1350.8738095238086, 1708.7857142857156, 1113.9833333333336, 1728.2309523809563, 1970.5571428571495, 2057.554761904766, 1219.238095238096, 1904.9238095238131, 1637.3714285714318, 1861.3809523809566, 2284.6547619047747, 1639.6071428571445, 1798.685714285719, 2035.1500000000071, 2049.7380952381013, 1967.573809523815, 1768.9642857142892, 1798.9666666666726, 1705.8238095238123, 1198.4476190476182, 1386.223809523812, 2048.1785714285775, 1450.5833333333337, 2330.535714285723, 1743.8428571428624, 1799.1904761904814, 2268.1357142857255, 1539.2380952380963, 1606.7952380952397, 1858.9690476190515, 2196.3809523809605, 1195.357142857142, 1770.5404761904806, 2283.833333333343, 1420.250000000003, 1679.3976190476208, 2138.6571428571515, 2070.8666666666722, 1138.0761904761903, 1768.150000000003, 1941.1476190476233, 1716.5785714285742, 2026.4761904761967, 1386.5190476190498, 1665.673809523814, 1521.0785714285737, 1690.178571428575, 2045.083333333343, 1514.195238095238, 1861.8857142857196, 1925.3928571428637, 1706.49047619048, 1453.9976190476202, 1446.4619047619087, 2037.1714285714363, 1375.6809523809545, 2462.7238095238217, 1674.7952380952413, 2143.4523809523907, 1401.0761904761926, 2123.2285714285786, 2330.933333333339, 1302.7095238095242, 1249.7809523809515, 1588.566666666668, 2132.9119047619133, 2267.0476190476274, 2176.6214285714354, 2095.642857142863, 1509.8190476190518, 2200.5238095238137, 1805.3976190476267, 1515.228571428573, 1615.6214285714302, 1966.1404761904846, 2256.6238095238173, 1856.91190476191, 2018.3380952381, 2237.259523809532, 1595.4357142857157, 2603.645238095249, 1671.914285714289, 2071.464285714289, 1117.133333333333, 1393.414285714286, 1730.3452380952447, 1567.8500000000008, 2069.900000000005, 1699.5142857142885, 2180.6523809523896]\n",
    "print(\"Used:\", sum(used) / len(used))\n",
    "print(\"Not Used:\", sum(not_used) / len(not_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972.3195714285746 314.6977080375041\n",
      "1838.7698095238154 232.44030377041082\n"
     ]
    }
   ],
   "source": [
    "used = [1427.7666666666678, 1549.5857142857142, 1738.5166666666669, 1831.488095238098, 1731.5928571428597, 2157.678571428574, 2128.9357142857184, 2192.864285714291, 1574.5071428571418, 1727.204761904761, 2247.41666666667, 1517.788095238097, 2282.1452380952414, 2244.119047619051, 2173.678571428576, 2023.3309523809553, 1754.26666666667, 2253.200000000006, 1742.6809523809573, 2183.11428571429, 2234.5166666666723, 1787.8166666666673, 1947.914285714286, 1456.6880952380934, 2362.688095238105, 1694.0642857142877, 2154.309523809528, 2095.9880952381004, 1587.123809523813, 1644.7952380952406, 2499.538095238106, 2190.840476190481, 1901.9976190476225, 2282.1214285714336, 2489.1928571428657, 1606.6285714285686, 2454.780952380964, 1573.4928571428588, 2120.411904761908, 1339.5190476190505, 1907.9452380952407, 2364.4880952381013, 1808.4166666666683, 1922.7880952380951, 1915.3, 2348.3357142857185, 2047.39523809524, 1733.05238095238, 2104.7261904761926, 2557.221428571439]\n",
    "\n",
    "b = [1898.5809523809592, 2167.719047619056, 2234.957142857154, 1898.3714285714348, 2175.1952380952443, 2004.1047619047695, 1864.685714285718, 2013.100000000006, 1550.080952380953, 1908.8238095238191, 1840.2904761904845, 2130.238095238103, 1934.1190476190545, 1468.8000000000009, 2055.871428571436, 1978.7809523809592, 1607.1000000000035, 1980.6619047619104, 1471.466666666667, 1967.2142857142937, 1869.347619047623, 1548.5380952380988, 1949.5857142857226, 1738.3523809523888, 1688.7190476190526, 1587.5142857142894, 1871.7714285714337, 2030.3904761904835, 2054.3095238095325, 1964.1142857142922, 1804.023809523816, 1354.9809523809563, 1652.0380952380974, 1807.952380952386, 1810.2476190476232, 1762.1857142857184, 1897.50952380953, 1974.2714285714349, 1716.2000000000037, 2056.666666666678, 1622.9047619047665, 2340.2380952381036, 1586.1523809523853, 2275.185714285727, 1277.2142857142846, 1579.6047619047665, 1688.4428571428634, 1850.7333333333395, 1751.6285714285757, 1677.5047619047655]\n",
    "\n",
    "print(np.mean(used), np.std(used))\n",
    "print(np.mean(b), np.std(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_5.graphml\n",
      "Total alert paths: 4621. Expected: alert_num ^ 2 = 4624, Selected: 4621\n",
      "Path length: 4621 Train ratio: 0.9783596624107336\n",
      "Median score: 4536.233333333362 High score: 5395.499999999955 Low score: 2853.0333333333633\n",
      "Total test set: 0\n"
     ]
    }
   ],
   "source": [
    "from secgym.qagen.alert_graph import AlertGraph\n",
    "import os \n",
    "import json\n",
    "\n",
    "# def compute_overlap_score(path1, path2, beta=0.01, delta=0):\n",
    "#     \"\"\"\n",
    "#     Calculate an overlap score between two paths, inspired by the Jaccard Index,\n",
    "#     with a small penalty for unshared edges.\n",
    "\n",
    "#     Parameters:\n",
    "#         path1 (list): The first path as a sequence of nodes.\n",
    "#         path2 (list): The second path as a sequence of nodes.\n",
    "#         beta (float): Weight for penalizing unshared edges.\n",
    "#         delta (float): Baseline adjustment to ensure non-negativity (optional).\n",
    "\n",
    "#     Returns:\n",
    "#         float: Overlap score.\n",
    "#     \"\"\"\n",
    "#     # Get edges for both paths\n",
    "#     edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "#     edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "#     # Calculate shared and unshared edges\n",
    "#     shared_edges = edges1 & edges2\n",
    "#     unshared_edges = edges1 ^ edges2  # Symmetric difference\n",
    "#     total_edges = edges1 | edges2    # Union of all edges\n",
    "\n",
    "#     # Compute Jaccard Index-inspired score with penalty for unshared edges\n",
    "#     jaccard_score = len(shared_edges) / len(total_edges) if total_edges else 0\n",
    "#     penalty = beta * len(unshared_edges) / len(total_edges) if total_edges else 0\n",
    "#     score = jaccard_score - penalty\n",
    "\n",
    "#     # Add baseline adjustment to ensure non-negativity\n",
    "#     # score = max(0, score + delta)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "def compute_overlap_score(path1, path2, alpha=3, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate the overlap score between two paths based on shared and unshared edges.\n",
    "\n",
    "    Parameters:\n",
    "        path (list): The first path as a sequence of nodes.\n",
    "        other_path (list): The second path as a sequence of nodes.\n",
    "        alpha (float): Weight for shared edges (positive contribution).\n",
    "        beta (float): Weight for unshared edges (negative contribution).\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap score.\n",
    "    \"\"\"\n",
    "    if len(path1) <= 1 or len(path2) <= 1:\n",
    "        return 0\n",
    "    # Get edges for both paths\n",
    "    edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "    edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "    # Shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    if len(shared_edges) == 0:\n",
    "        return 0\n",
    "    unshared_edges = edges1 ^ edges2 \n",
    "\n",
    "    # Compute score\n",
    "    score = alpha * len(shared_edges) - beta * len(unshared_edges) / (len(edges1) + len(edges2))\n",
    "    # bound: [-beta, alpha]\n",
    "    # resacle to [0, 1]\n",
    "    # score = (score + beta) / (alpha + beta)\n",
    " \n",
    "    return score\n",
    "\n",
    "def split_train_test(all_paths:dict, train_ratio:float = 0.9, trials=5):\n",
    "    \"\"\"\n",
    "    all_path = [{'start_alert': int, 'end_alert': int}, ...]\n",
    "\n",
    "    {\n",
    "        'start_alert': 24,\n",
    "        'end_alert': 11,\n",
    "        'start_entities': [12],\n",
    "        'end_entities': [9],\n",
    "        'shortest_alert_path': [24, 9, 11]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # construct a dictionary to map the path to the original dictionary\n",
    "    random.shuffle(all_paths)\n",
    "    path_to_dict = {}\n",
    "    for path in all_paths:\n",
    "        # extract the 0, 2, 4, 6, ... index of the path\n",
    "        extracted = path['shortest_alert_path'][::2]\n",
    "        path_to_dict[tuple(extracted)] = path\n",
    "    \n",
    "    # prepare the alert paths\n",
    "    alert_paths = list(path_to_dict.keys())\n",
    "    max_length = max(len(p) for p in alert_paths)\n",
    "    total = len(alert_paths)\n",
    "    train_len = int(total * train_ratio)\n",
    "    test_len = total - train_len\n",
    "\n",
    "    # length weight\n",
    "    lweights = []\n",
    "    for p in alert_paths:\n",
    "        lweights.append(len(p) / max_length)\n",
    "    lweights = np.array(lweights)\n",
    "    lweights = lweights / lweights.sum()\n",
    "    avg = lweights.mean()\n",
    "\n",
    "    score_matrix = [[-1000] * len(alert_paths)  for _ in range(len(alert_paths))]\n",
    "\n",
    "    # helper function to get the score\n",
    "    def get_score(i, j):\n",
    "        if score_matrix[i][j] != -1000:\n",
    "            return score_matrix[i][j]\n",
    "        if i==j:\n",
    "            score_matrix[i][j] = 0\n",
    "            return 0\n",
    "        elif score_matrix[j][i] != -1000:\n",
    "            score_matrix[i][j] = score_matrix[j][i]\n",
    "            return score_matrix[i][j]\n",
    "        score_matrix[i][j] = compute_overlap_score(alert_paths[i], alert_paths[j])\n",
    "        return score_matrix[i][j]\n",
    "\n",
    "    # random split and compare\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    score_splits = {}\n",
    "    for _ in range(trials):\n",
    "        for i in range(total):\n",
    "            if len(train_keys) >= train_len:\n",
    "                test_keys += alert_paths[i:]\n",
    "                break\n",
    "            elif len(test_keys) >= test_len:\n",
    "                train_keys += alert_paths[i:]\n",
    "                break\n",
    "            if random.random() < (lweights[i] / (lweights[i] + avg)):\n",
    "                train_keys.append(alert_paths[i])\n",
    "            else:\n",
    "                test_keys.append(alert_paths[i])\n",
    "\n",
    "        compare_score = 0\n",
    "        for k in train_keys:\n",
    "            for j in test_keys:\n",
    "                compare_score += get_score(alert_paths.index(k), alert_paths.index(j))\n",
    "\n",
    "        score_splits[compare_score] = (train_keys, test_keys)\n",
    "        train_keys = []\n",
    "        test_keys = []\n",
    "\n",
    "    # assert len(final_train_set) + len(final_test_set) == total, f\"Length mismatch: {len(final_train_set)} + {len(final_test_set)} != {total}\"\n",
    "    return score_splits, path_to_dict\n",
    "\n",
    "graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files\"\n",
    "qa_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_path\"\n",
    "\n",
    "train_total_count = 0\n",
    "test_total_count = 0\n",
    "\n",
    "median_score_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/media_split\"\n",
    "high_score_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/high_split\"\n",
    "low_score_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/low_split\"\n",
    "\n",
    "# create\n",
    "os.makedirs(median_score_path, exist_ok=True)\n",
    "os.makedirs(high_score_path, exist_ok=True)\n",
    "os.makedirs(low_score_path, exist_ok=True)\n",
    "\n",
    "def save_to_split(path, filename, train_keys, test_keys, path_to_dict):\n",
    "    with open(os.path.join(path, filename.split(\".\")[0] + \".json\"), \"w\") as f:\n",
    "        train_set = [path_to_dict[p1] for p1 in train_keys]\n",
    "        test_set = [path_to_dict[p2] for p2 in test_keys]\n",
    "        json.dump({\"train\": train_set, \"test\": test_set}, f)\n",
    "\n",
    "for filename in os.listdir(graph_path):\n",
    "    if filename.endswith(\".graphml\"):\n",
    "        if \"_5.\" not in filename:\n",
    "            continue\n",
    "        print(filename)\n",
    "\n",
    "        graphfile = graph_path + \"/\" + filename\n",
    "        alert_graph = AlertGraph()\n",
    "        alert_graph.load_graph_from_graphml(graphfile)\n",
    "        all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "\n",
    "        if len(all_paths) < 150:\n",
    "            train_ratio = 0.288\n",
    "            # trials = 20\n",
    "        else:\n",
    "            train_ratio = 1 - 100 / len(all_paths)\n",
    "        print(\"Path length:\", len(all_paths), \"Train ratio:\", train_ratio)\n",
    "\n",
    "        score_splits, path_to_dict = split_train_test(all_paths, train_ratio, trials=50)\n",
    "\n",
    "        # save high, low, median score\n",
    "        scores = list(score_splits.keys())\n",
    "        scores.sort()\n",
    "        median = scores[len(scores) // 2]\n",
    "        high = scores[-1]\n",
    "        low = scores[0]\n",
    "\n",
    "        save_to_split(median_score_path, filename, *score_splits[median], path_to_dict)\n",
    "        save_to_split(high_score_path, filename, *score_splits[high], path_to_dict)\n",
    "        save_to_split(low_score_path, filename, *score_splits[low], path_to_dict)\n",
    "        \n",
    "        print(\"Median score:\", median, \"High score:\", high, \"Low score:\", low)\n",
    "    \n",
    "\n",
    "        # qafile = qa_path + \"/\" + filename.split(\".\")[0] + \".json\"\n",
    "        # if os.path.exists(qafile):\n",
    "        #     # get best score\n",
    "        #     with open(qafile, \"r\") as f:\n",
    "        #         data = json.load(f)\n",
    "        #         best_score = data[\"score\"]\n",
    "        #         print(\"New best score:\", score, \"Old best score:\", best_score)\n",
    "        #         if score > best_score:\n",
    "        #             print(\"New best score is better, update\")\n",
    "        #             with open(qafile, \"w\") as f:\n",
    "        #                 json.dump({\"train\": train_set, \"test\": test_set, \"score\": score}, f)\n",
    "        #         else:\n",
    "        #             print(\"Old best score is better, skip\")\n",
    "        # else:\n",
    "        #     with open(qafile, \"w\") as f:\n",
    "        #         json.dump({\"train\": train_set, \"test\": test_set, \"score\": score}, f)\n",
    "            \n",
    "        # print(\"Train set:\", len(train_set), \"Test set:\", len(test_set))\n",
    "        # train_total_count += len(train_set)\n",
    "        # test_total_count += len(test_set)\n",
    "        # print(\"-\"*100)\n",
    "\n",
    "print(\"Total test set:\", test_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question, answer -> Training\n",
    "\n",
    "question -> Baseline -> Trajectory, Reward=1 \n",
    "\n",
    "get all the correct trajectories -> S -> A A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_overlap_score(path1, path2, beta=0.01, delta=0):\n",
    "#     \"\"\"\n",
    "#     Calculate an overlap score between two paths, inspired by the Jaccard Index,\n",
    "#     with a small penalty for unshared edges.\n",
    "\n",
    "#     Parameters:\n",
    "#         path1 (list): The first path as a sequence of nodes.\n",
    "#         path2 (list): The second path as a sequence of nodes.\n",
    "#         beta (float): Weight for penalizing unshared edges.\n",
    "#         delta (float): Baseline adjustment to ensure non-negativity (optional).\n",
    "\n",
    "#     Returns:\n",
    "#         float: Overlap score.\n",
    "#     \"\"\"\n",
    "#     # Get edges for both paths\n",
    "#     edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "#     edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "#     # Calculate shared and unshared edges\n",
    "#     shared_edges = edges1 & edges2\n",
    "#     unshared_edges = edges1 ^ edges2  # Symmetric difference\n",
    "#     total_edges = edges1 | edges2    # Union of all edges\n",
    "\n",
    "#     # Compute Jaccard Index-inspired score with penalty for unshared edges\n",
    "#     jaccard_score = len(shared_edges) / len(total_edges) if total_edges else 0\n",
    "#     penalty = beta * len(unshared_edges) / len(total_edges) if total_edges else 0\n",
    "#     score = jaccard_score - penalty\n",
    "\n",
    "#     # Add baseline adjustment to ensure non-negativity\n",
    "#     # score = max(0, score + delta)\n",
    "\n",
    "#     return score\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "zero_count = 0\n",
    "noshare_count = 0\n",
    "\n",
    "def compute_overlap_score(path1, path2, alpha=3, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate the overlap score between two paths based on shared and unshared edges.\n",
    "\n",
    "    Parameters:\n",
    "        path (list): The first path as a sequence of nodes.\n",
    "        other_path (list): The second path as a sequence of nodes.\n",
    "        alpha (float): Weight for shared edges (positive contribution).\n",
    "        beta (float): Weight for unshared edges (negative contribution).\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap score.\n",
    "    \"\"\"\n",
    "    if len(path1) <= 1 or len(path2) <= 1:\n",
    "        return 0\n",
    "    # Get edges for both paths\n",
    "    edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "    edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "    # Shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    if len(shared_edges) == 0:\n",
    "        return 0\n",
    "    unshared_edges = edges1 ^ edges2 \n",
    "\n",
    "    # Compute score\n",
    "    score = alpha * len(shared_edges) - beta * len(unshared_edges) / (len(edges1) + len(edges2))\n",
    "    # bound: [-beta, alpha]\n",
    "    # resacle to [0, 1]\n",
    "    # score = (score + beta) / (alpha + beta)\n",
    " \n",
    "    return score\n",
    "\n",
    "def split_train_test(all_paths:dict, train_ratio:float = 0.9):\n",
    "    \"\"\"\n",
    "    all_path = [{'start_alert': int, 'end_alert': int}, ...]\n",
    "\n",
    "    {\n",
    "        'start_alert': 24,\n",
    "        'end_alert': 11,\n",
    "        'start_entities': [12],\n",
    "        'end_entities': [9],\n",
    "        'shortest_alert_path': [24, 9, 11]\n",
    "    }\n",
    "    \"\"\"\n",
    "    # construct a dictionary to map the path to the original dictionary\n",
    "    random.shuffle(all_paths)\n",
    "    path_to_dict = {}\n",
    "    for path in all_paths:\n",
    "        # extract the 0, 2, 4, 6, ... index of the path\n",
    "        extracted = path['shortest_alert_path'][::2]\n",
    "        path_to_dict[tuple(extracted)] = path\n",
    "    \n",
    "    # prepare the alert paths\n",
    "    alert_paths = list(path_to_dict.keys())\n",
    "    max_length = max(len(p) for p in alert_paths)\n",
    "    total = len(alert_paths)\n",
    "    train_len = int(total * train_ratio)\n",
    "    test_len = total - train_len\n",
    "\n",
    "    # length weight\n",
    "    lweights = []\n",
    "    for p in alert_paths:\n",
    "        lweights.append(len(p) / max_length)\n",
    "    lweights = np.array(lweights)\n",
    "    lweights = lweights / lweights.sum()\n",
    "\n",
    "    score_matrix = [[-1000] * len(alert_paths)  for _ in range(len(alert_paths))]\n",
    "    def get_score(i, j):\n",
    "        if score_matrix[i][j] != -1000:\n",
    "            return score_matrix[i][j]\n",
    "        if i==j:\n",
    "            score_matrix[i][j] = 0\n",
    "            return 0\n",
    "        elif score_matrix[j][i] != -1000:\n",
    "            score_matrix[i][j] = score_matrix[j][i]\n",
    "            return score_matrix[i][j]\n",
    "        score_matrix[i][j] = compute_overlap_score(alert_paths[i], alert_paths[j])\n",
    "        return score_matrix[i][j]\n",
    "    \n",
    "    # non_sampled\n",
    "    remaining = alert_paths.copy()\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    unassigned_keys = alert_paths.copy()\n",
    "    for _ in range(total):\n",
    "        if len(train_keys) >= train_len:\n",
    "            break\n",
    "        if len(test_keys) >= test_len:\n",
    "            break\n",
    "        if train_keys == [] or test_keys == []:\n",
    "          sample_index = np.random.choice(1, (total), p=lweights)\n",
    "        else:\n",
    "            # for each unassigned, update the score afte the new sample is assigned\n",
    "        # p = remaining[sample_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # split the train and test set\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    for i in range(total):\n",
    "        p = alert_paths[i]\n",
    "        if train_keys == [] or test_keys == []:\n",
    "            ratio = 0.5\n",
    "        elif len(train_keys) >= train_len:\n",
    "            test_keys += alert_paths[i:]\n",
    "            break\n",
    "        elif len(test_keys) >= test_len:\n",
    "            train_keys += alert_paths[i:]\n",
    "            break\n",
    "        else:\n",
    "            train_score = sum(get_score(i, alert_paths.index(k)) for k in train_keys) / len(train_keys)\n",
    "            test_score = sum(get_score(i, alert_paths.index(k)) for k in test_keys) / len(test_keys)\n",
    "            # if train_score is higher, the point should be more likely to be in test set\n",
    "\n",
    "            try: \n",
    "                # use softmax\n",
    "                exp_train = np.exp(train_score)\n",
    "                exp_test = np.exp(test_score)\n",
    "                ratio = exp_train / (exp_train + exp_test)\n",
    "            except ZeroDivisionError:\n",
    "                ratio = 0.5\n",
    "\n",
    "            # print(\"len train:\", len(train_keys), \"len test:\", len(test_keys))\n",
    "            # print(\"Train score:\", train_score, \"Test score:\", test_score, \"Ratio:\", ratio)\n",
    "\n",
    "            # add length influence\n",
    "            # ratio = ratio * (theta / ( theta + len(p) / max_length))\n",
    "\n",
    "        # weighted random selection\n",
    "        if random.random() < ratio:\n",
    "            train_keys.append(p)\n",
    "        else:\n",
    "            test_keys.append(p)\n",
    "\n",
    "    # ----------------- compare with random selection -----------------\n",
    "    total_score = 0\n",
    "    for k in train_keys:\n",
    "        for j in test_keys:\n",
    "            total_score += get_score(alert_paths.index(k), alert_paths.index(j))\n",
    "    \n",
    "    # take first k as train set\n",
    "    compare_train_set = []\n",
    "    compare_test_set = []\n",
    "    for i in range(train_len):\n",
    "        if len(compare_train_set) >= train_len:\n",
    "            compare_test_set += alert_paths[i:]\n",
    "            break\n",
    "        elif len(compare_test_set) >= test_len:\n",
    "            compare_train_set += alert_paths[i:]\n",
    "            break\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            compare_train_set.append(alert_paths[i])\n",
    "        else:\n",
    "            compare_test_set.append(alert_paths[i])\n",
    "\n",
    "    compare_score = 0\n",
    "    for k in compare_train_set:\n",
    "        for j in compare_test_set:\n",
    "            compare_score += get_score(alert_paths.index(k), alert_paths.index(j))\n",
    "\n",
    "    print(\"Total score:\", total_score, \"Comparison score:\", compare_score)\n",
    "    # -----------------------------------------------------------------\n",
    "    return total_score, compare_score\n",
    "\n",
    "    # map back to original paths\n",
    "    final_train_set = [path_to_dict[p1] for p1 in train_keys]\n",
    "    final_test_set = [path_to_dict[p2] for p2 in test_keys]\n",
    "    return final_train_set, final_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total alert paths: 728. Expected: alert_num ^ 2 = 729, Selected: 728\n",
      "0.8626373626373627\n",
      "Total score: 1971.8095238095293 Comparison score: 1950.692857142863\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_ratio)\n\u001b[1;32m     24\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m split_train_test(all_paths)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_set))\n\u001b[1;32m     26\u001b[0m train_total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_set)\n\u001b[1;32m     27\u001b[0m test_total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_set)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "from secgym.qagen.alert_graph import AlertGraph\n",
    "import os \n",
    "\n",
    "graph_path = \"/Users/kevin/Downloads/SecRL/secgym/qagen/graph_files\"\n",
    "\n",
    "train_total_count = 0\n",
    "test_total_count = 0\n",
    "\n",
    "for filename in os.listdir(graph_path):\n",
    "    if filename.endswith(\".graphml\"):\n",
    "        if \"55\" not in filename:\n",
    "            continue\n",
    "        graphfile = graph_path + \"/\" + filename\n",
    "        alert_graph = AlertGraph()\n",
    "        alert_graph.load_graph_from_graphml(graphfile)\n",
    "        all_paths = alert_graph.get_alert_paths(verbose=False)\n",
    "\n",
    "        if len(all_paths) < 150:\n",
    "            train_ratio = 0.285\n",
    "        else:\n",
    "            train_ratio = 1 - 100 / len(all_paths)\n",
    "            print(train_ratio)\n",
    "\n",
    "        train_set, test_set = split_train_test(all_paths)\n",
    "        print(\"Train set:\", len(train_set), \"Test set:\", len(test_set))\n",
    "        train_total_count += len(train_set)\n",
    "        test_total_count += len(test_set)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # min_score = min(train_score, test_score)\n",
    "                # if min_score < 0:\n",
    "                #     train_score += abs(min_score)\n",
    "                #     test_score += abs(min_score)\n",
    "                # ratio = train_score / (train_score + test_score)\n",
    "                # print(\"Ratio:\", train_score, test_score, ratio)\n",
    "                # if ratio > 0.55 or ratio < 0.45:\n",
    "                #     large_ratio_count += 1\n",
    "\n",
    "            # train_score = 0\n",
    "            # for k in train_keys:\n",
    "            #     if score_matrix[i][alert_paths.index(k)] == -1:\n",
    "            #         score_matrix[i][alert_paths.index(k)] = compute_overlap_score(p, k)\n",
    "            #     train_score += score_matrix[i][alert_paths.index(k)]\n",
    "            \n",
    "            # test_score = 0\n",
    "            # for k in test_keys:\n",
    "            #     if score_matrix[i][alert_paths.index(k)] == -1:\n",
    "            #         score_matrix[i][alert_paths.index(k)] = compute_overlap_score(p, k)\n",
    "            #     test_score += score_matrix[i][alert_paths.index(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 1 len test: 1\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 1 len test: 2\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 1 len test: 3\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 1 len test: 4\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 4\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 5\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 6\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 7\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 8\n",
      "Train score: 0.0 Test score: 0.3333333333333333 Ratio: 0.4174297935376853\n",
      "len train: 2 len test: 9\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 10\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 11\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 12\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 13\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 14\n",
      "Train score: 0.0 Test score: 0.17142857142857143 Ratio: 0.4572475058826808\n",
      "len train: 2 len test: 15\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 16\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 17\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 18\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 2 len test: 19\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 19\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 20\n",
      "Train score: 0.0 Test score: 0.36500000000000005 Ratio: 0.40974974806981657\n",
      "len train: 3 len test: 21\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 22\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 23\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 24\n",
      "Train score: 0.0 Test score: 0.10416666666666667 Ratio: 0.4739818553246543\n",
      "len train: 3 len test: 25\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 26\n",
      "Train score: 0.0 Test score: 0.09615384615384616 Ratio: 0.47598004211153444\n",
      "len train: 3 len test: 27\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 28\n",
      "Train score: 0.7999999999999999 Test score: 0.0 Ratio: 0.6899744811276124\n",
      "len train: 3 len test: 29\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 30\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 31\n",
      "Train score: 0.0 Test score: 0.07741935483870968 Ratio: 0.4806548228486605\n",
      "len train: 3 len test: 32\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 3 len test: 33\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 33\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 34\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 35\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 36\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 37\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 4 len test: 38\n",
      "Train score: 0.625 Test score: 0.0 Ratio: 0.6513548646660542\n",
      "len train: 5 len test: 38\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 5 len test: 39\n",
      "Train score: 0.0 Test score: 0.12136752136752137 Ratio: 0.46969530972620055\n",
      "len train: 5 len test: 40\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 40\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 41\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 42\n",
      "Train score: 0.0 Test score: 0.05714285714285714 Ratio: 0.485718171714586\n",
      "len train: 6 len test: 43\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 44\n",
      "Train score: 0.0 Test score: 0.05303030303030303 Ratio: 0.48674553029622347\n",
      "len train: 6 len test: 45\n",
      "Train score: 0.9444444444444445 Test score: 0.05185185185185186 Ratio: 0.7094249027745428\n",
      "len train: 6 len test: 46\n",
      "Train score: 0.0 Test score: 0.05217391304347826 Ratio: 0.4869594797569719\n",
      "len train: 6 len test: 47\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 48\n",
      "Train score: 1.2055555555555555 Test score: 0.04861111111111111 Ratio: 0.7607770612060926\n",
      "len train: 6 len test: 49\n",
      "Train score: 0.0 Test score: 0.09795918367346938 Ratio: 0.47552976898423266\n",
      "len train: 6 len test: 50\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 51\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 6 len test: 52\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 7 len test: 52\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 7 len test: 53\n",
      "Train score: 0.0 Test score: 0.14465408805031446 Ratio: 0.4638994058697566\n",
      "len train: 7 len test: 54\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 7 len test: 55\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 7 len test: 56\n",
      "Train score: 0.0 Test score: 0.044642857142857144 Ratio: 0.48884113893933706\n",
      "len train: 7 len test: 57\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 7 len test: 58\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 58\n",
      "Train score: 0.0 Test score: 0.040229885057471264 Ratio: 0.4899438849703437\n",
      "len train: 8 len test: 59\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 60\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 61\n",
      "Train score: 0.0 Test score: 0.04371584699453552 Ratio: 0.4890727784245248\n",
      "len train: 8 len test: 62\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 63\n",
      "Train score: 0.0 Test score: 0.3482993197278911 Ratio: 0.41379489227964644\n",
      "len train: 8 len test: 64\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 65\n",
      "Train score: 0.0 Test score: 0.0 Ratio: 0.5\n",
      "len train: 8 len test: 66\n",
      "Train score: 0.0 Test score: 0.07575757575757576 Ratio: 0.4810696589620313\n",
      "len train: 8 len test: 67\n",
      "Train score: 0.0 Test score: 0.03582089552238806 Ratio: 0.4910457335611444\n",
      "len train: 8 len test: 68\n",
      "Train score: 0.0 Test score: 0.10567226890756301 Ratio: 0.4736064887477454\n",
      "len train: 8 len test: 69\n",
      "Train score: 0.0 Test score: 0.03864734299516908 Ratio: 0.4903393666618882\n",
      "len train: 8 len test: 70\n",
      "Train score: 0.0 Test score: 0.03428571428571429 Ratio: 0.4914294109800272\n",
      "len train: 8 len test: 71\n",
      "Train score: 0.0 Test score: 0.035211267605633804 Ratio: 0.49119809248801855\n",
      "len train: 8 len test: 72\n",
      "Train score: 0.0 Test score: 0.03240740740740741 Ratio: 0.49189885714779746\n",
      "Zero ratio count: 0\n",
      "Large ratio count: 0\n",
      "Total score: 1867.0833333333392 Comparison score: 1607.3857142857173\n"
     ]
    }
   ],
   "source": [
    "pp = split_train_test(all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # print(len(train_keys), len(test_keys))\n",
    "    # print(train_len, total)    \n",
    "    # print(len(compare_train_set), len(compare_test_set))\n",
    "\n",
    "    # total_lenth_test = 0\n",
    "    # for k in test_keys:\n",
    "    #     total_lenth_test += len(k)\n",
    "    # print(\"Total length test:\", total_lenth_test)\n",
    "    # total_score = 0\n",
    "    \n",
    "    # total_lenth_test = 0\n",
    "    # for k in compare_test_set:\n",
    "    #     total_lenth_test += len(k)\n",
    "    # print(\"Total length test compare:\", total_lenth_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_overlap_score(path1, path2, alpha=3, beta=1):\n",
    "    \"\"\"\n",
    "    Calculate the overlap score between two paths based on shared and unshared edges.\n",
    "\n",
    "    Parameters:\n",
    "        path (list): The first path as a sequence of nodes.\n",
    "        other_path (list): The second path as a sequence of nodes.\n",
    "        alpha (float): Weight for shared edges (positive contribution).\n",
    "        beta (float): Weight for unshared edges (negative contribution).\n",
    "\n",
    "    Returns:\n",
    "        float: Overlap score.\n",
    "    \"\"\"\n",
    "    global zero_count\n",
    "    global noshare_count\n",
    "    if len(path1) <= 1 or len(path2) <= 1:\n",
    "        zero_count += 1\n",
    "        return 0\n",
    "    # Get edges for both paths\n",
    "    edges1 = set((path1[i], path1[i + 1]) for i in range(len(path1) - 1))\n",
    "    edges2 = set((path2[i], path2[i + 1]) for i in range(len(path2) - 1))\n",
    "    \n",
    "    # Calculate shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    if len(shared_edges) == 0:\n",
    "        noshare_count += 1\n",
    "    unshared_edges = edges1 ^ edges2  # Symmetric difference: edges in one but not both\n",
    "\n",
    "    # Shared and unshared edges\n",
    "    shared_edges = edges1 & edges2\n",
    "    unshared_edges = edges1 ^ edges2 \n",
    "\n",
    "    # Compute score\n",
    "    score = (alpha * 2 * len(shared_edges) - beta * len(unshared_edges)) / (len(edges1) + len(edges2))\n",
    "    # bound: [-beta, alpha]\n",
    "    # resacle to [0, 1]\n",
    "    score = (score + beta) / (alpha + beta)\n",
    "\n",
    "    return score\n",
    "\n",
    "print(compute_overlap_score([1,2,3,4,5], [4,5]))\n",
    "print(compute_overlap_score([1,2,3,4,5], [6,4,5,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19230769230769137"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0142857142857142 / (.0142857142857142+.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19230769230769137"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0142857142857142 / (.0142857142857142+.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_count\n",
    "# noshare_count|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pp)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pp)):\n\u001b[0;32m----> 5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[1;32m      6\u001b[0m             zcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m zcount        \n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "zcount = 0\n",
    "for i in range(len(pp)):\n",
    "    for j in range(len(pp)):\n",
    "\n",
    "        if pp[i][j] < 0:\n",
    "            zcount += 1\n",
    "zcount        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529984"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "728*728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(500, 700):\n",
    "    print(pp[i][100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in pp.items():\n",
    "#     print(k, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18577"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242275"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noshare_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
